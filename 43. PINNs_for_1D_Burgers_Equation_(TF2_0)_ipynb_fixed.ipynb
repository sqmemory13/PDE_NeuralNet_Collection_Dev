{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PINNs for 1D Burgers Equation (TF2.0).ipynb fixed",
      "provenance": [],
      "collapsed_sections": [
        "A1Mj-RBCn8MZ",
        "GkimJNtepkKi",
        "QGd5zVtoxAqt",
        "bXtJ5GiaxAqw",
        "dOPzdkKsJzA4",
        "OTxvp1nJGDeb",
        "fGrMDRc3w1ex",
        "rRGW4IW0w1e0"
      ]
    },
    "jupytext": {
      "encoding": "# -*- coding: utf-8 -*-",
      "formats": "ipynb,py:light",
      "main_language": "python"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://github.com/pierremtb/PINNs-TF2.0"
      ],
      "metadata": {
        "id": "TKDuovkI0gZn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Mj-RBCn8MZ"
      },
      "source": [
        "# 0. Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al80f-lPoJjh"
      },
      "source": [
        "## Getting the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3iHOMsdnNiq",
        "outputId": "cf6b1528-ed45-4a7e-b0d9-2bf8e3000ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/maziarraissi/PINNs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PINNs'...\n",
            "remote: Enumerating objects: 741, done.\u001b[K\n",
            "remote: Total 741 (delta 0), reused 0 (delta 0), pack-reused 741\u001b[K\n",
            "Receiving objects: 100% (741/741), 474.47 MiB | 17.92 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "Checking out files: 100% (561/561), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtoc_dXgoOZq"
      },
      "source": [
        "## Setting up modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNMtDjXkFHaN"
      },
      "source": [
        "TeX packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaZCKcDsEVRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6ba1ef-30d1-48b7-aa7c-0b6801a1c332"
      },
      "source": [
        "!sudo apt-get -qq install texlive-fonts-recommended texlive-fonts-extra dvipng"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 86.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../04-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../05-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../06-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../07-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../08-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../09-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../10-libcupsimage2_2.2.7-1ubuntu2.9_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../13-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.16_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../14-libgs9_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../15-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../16-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../17-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../18-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.16_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../19-dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package fonts-adf-accanthis.\n",
            "Preparing to unpack .../20-fonts-adf-accanthis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-accanthis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-berenis.\n",
            "Preparing to unpack .../21-fonts-adf-berenis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-berenis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-gillius.\n",
            "Preparing to unpack .../22-fonts-adf-gillius_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-gillius (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-adf-universalis.\n",
            "Preparing to unpack .../23-fonts-adf-universalis_0.20110505-1_all.deb ...\n",
            "Unpacking fonts-adf-universalis (0.20110505-1) ...\n",
            "Selecting previously unselected package fonts-cabin.\n",
            "Preparing to unpack .../24-fonts-cabin_1.5-2_all.deb ...\n",
            "Unpacking fonts-cabin (1.5-2) ...\n",
            "Selecting previously unselected package fonts-comfortaa.\n",
            "Preparing to unpack .../25-fonts-comfortaa_3.001-2_all.deb ...\n",
            "Unpacking fonts-comfortaa (3.001-2) ...\n",
            "Selecting previously unselected package fonts-croscore.\n",
            "Preparing to unpack .../26-fonts-croscore_20171026-2_all.deb ...\n",
            "Unpacking fonts-croscore (20171026-2) ...\n",
            "Selecting previously unselected package fonts-crosextra-caladea.\n",
            "Preparing to unpack .../27-fonts-crosextra-caladea_20130214-2_all.deb ...\n",
            "Unpacking fonts-crosextra-caladea (20130214-2) ...\n",
            "Selecting previously unselected package fonts-crosextra-carlito.\n",
            "Preparing to unpack .../28-fonts-crosextra-carlito_20130920-1_all.deb ...\n",
            "Unpacking fonts-crosextra-carlito (20130920-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../29-fonts-dejavu-core_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../30-fonts-dejavu-extra_2.37-1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond.\n",
            "Preparing to unpack .../31-fonts-ebgaramond_0.016-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond (0.016-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond-extra.\n",
            "Preparing to unpack .../32-fonts-ebgaramond-extra_0.016-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond-extra (0.016-1) ...\n",
            "Selecting previously unselected package fonts-font-awesome.\n",
            "Preparing to unpack .../33-fonts-font-awesome_4.7.0~dfsg-3_all.deb ...\n",
            "Unpacking fonts-font-awesome (4.7.0~dfsg-3) ...\n",
            "Selecting previously unselected package fonts-freefont-otf.\n",
            "Preparing to unpack .../34-fonts-freefont-otf_20120503-7_all.deb ...\n",
            "Unpacking fonts-freefont-otf (20120503-7) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../35-fonts-freefont-ttf_20120503-7_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-7) ...\n",
            "Selecting previously unselected package fonts-gfs-artemisia.\n",
            "Preparing to unpack .../36-fonts-gfs-artemisia_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-artemisia (1.1-5) ...\n",
            "Selecting previously unselected package fonts-gfs-complutum.\n",
            "Preparing to unpack .../37-fonts-gfs-complutum_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-complutum (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-didot.\n",
            "Preparing to unpack .../38-fonts-gfs-didot_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-didot (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-neohellenic.\n",
            "Preparing to unpack .../39-fonts-gfs-neohellenic_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-neohellenic (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-olga.\n",
            "Preparing to unpack .../40-fonts-gfs-olga_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-olga (1.1-5) ...\n",
            "Selecting previously unselected package fonts-gfs-solomos.\n",
            "Preparing to unpack .../41-fonts-gfs-solomos_1.1-5_all.deb ...\n",
            "Unpacking fonts-gfs-solomos (1.1-5) ...\n",
            "Selecting previously unselected package fonts-go.\n",
            "Preparing to unpack .../42-fonts-go_0~20161116-1_all.deb ...\n",
            "Unpacking fonts-go (0~20161116-1) ...\n",
            "Selecting previously unselected package fonts-junicode.\n",
            "Preparing to unpack .../43-fonts-junicode_1.001-2_all.deb ...\n",
            "Unpacking fonts-junicode (1.001-2) ...\n",
            "Selecting previously unselected package fonts-linuxlibertine.\n",
            "Preparing to unpack .../44-fonts-linuxlibertine_5.3.0-4_all.deb ...\n",
            "Unpacking fonts-linuxlibertine (5.3.0-4) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../45-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-lobster.\n",
            "Preparing to unpack .../46-fonts-lobster_2.0-2_all.deb ...\n",
            "Unpacking fonts-lobster (2.0-2) ...\n",
            "Selecting previously unselected package fonts-lobstertwo.\n",
            "Preparing to unpack .../47-fonts-lobstertwo_2.0-2_all.deb ...\n",
            "Unpacking fonts-lobstertwo (2.0-2) ...\n",
            "Selecting previously unselected package fonts-noto-hinted.\n",
            "Preparing to unpack .../48-fonts-noto-hinted_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-hinted (20171026-2) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../49-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package fonts-oflb-asana-math.\n",
            "Preparing to unpack .../50-fonts-oflb-asana-math_000.907-6_all.deb ...\n",
            "Unpacking fonts-oflb-asana-math (000.907-6) ...\n",
            "Selecting previously unselected package fonts-open-sans.\n",
            "Preparing to unpack .../51-fonts-open-sans_1.11-1_all.deb ...\n",
            "Unpacking fonts-open-sans (1.11-1) ...\n",
            "Selecting previously unselected package fonts-roboto-hinted.\n",
            "Preparing to unpack .../52-fonts-roboto-hinted_2%3a0~20160106-2_all.deb ...\n",
            "Unpacking fonts-roboto-hinted (2:0~20160106-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentium.\n",
            "Preparing to unpack .../53-fonts-sil-gentium_20081126%3a1.03-2_all.deb ...\n",
            "Unpacking fonts-sil-gentium (20081126:1.03-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentium-basic.\n",
            "Preparing to unpack .../54-fonts-sil-gentium-basic_1.102-1_all.deb ...\n",
            "Unpacking fonts-sil-gentium-basic (1.102-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus.\n",
            "Preparing to unpack .../55-fonts-sil-gentiumplus_5.000-2_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus (5.000-2) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus-compact.\n",
            "Preparing to unpack .../56-fonts-sil-gentiumplus-compact_5.000-2_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus-compact (5.000-2) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../57-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../58-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../59-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../60-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../61-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../62-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../63-ruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../64-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../65-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../66-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../67-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../68-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../69-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../70-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../71-libruby2.5_2.5.1-1ubuntu1.12_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../72-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../73-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../74-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../75-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra.\n",
            "Preparing to unpack .../76-texlive-fonts-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-fonts-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package fonts-stix.\n",
            "Preparing to unpack .../77-fonts-stix_1.1.1-4_all.deb ...\n",
            "Unpacking fonts-stix (1.1.1-4) ...\n",
            "Selecting previously unselected package texlive-fonts-extra-links.\n",
            "Preparing to unpack .../78-texlive-fonts-extra-links_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-fonts-extra-links (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../79-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../80-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../81-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../82-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../83-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../84-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../85-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-gfs-neohellenic (1.1-6) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up fonts-stix (1.1.1-4) ...\n",
            "Setting up fonts-comfortaa (3.001-2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up fonts-dejavu-core (2.37-1) ...\n",
            "Setting up fonts-linuxlibertine (5.3.0-4) ...\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-oflb-asana-math (000.907-6) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up fonts-lobster (2.0-2) ...\n",
            "Setting up fonts-gfs-solomos (1.1-5) ...\n",
            "Setting up fonts-adf-accanthis (0.20110505-1) ...\n",
            "Setting up fonts-freefont-otf (20120503-7) ...\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up fonts-open-sans (1.11-1) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-crosextra-carlito (20130920-1) ...\n",
            "Setting up fonts-ebgaramond-extra (0.016-1) ...\n",
            "Setting up fonts-font-awesome (4.7.0~dfsg-3) ...\n",
            "Setting up fonts-junicode (1.001-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up fonts-gfs-complutum (1.1-6) ...\n",
            "Setting up fonts-cabin (1.5-2) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.9) ...\n",
            "Setting up fonts-sil-gentiumplus-compact (5.000-2) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up fonts-adf-gillius (0.20110505-1) ...\n",
            "Setting up fonts-crosextra-caladea (20130214-2) ...\n",
            "Setting up fonts-noto-hinted (20171026-2) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up fonts-ebgaramond (0.016-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up fonts-croscore (20171026-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up fonts-adf-berenis (0.20110505-1) ...\n",
            "Setting up fonts-adf-universalis (0.20110505-1) ...\n",
            "Setting up fonts-sil-gentiumplus (5.000-2) ...\n",
            "Setting up fonts-gfs-didot (1.1-6) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up fonts-gfs-artemisia (1.1-5) ...\n",
            "Setting up fonts-dejavu-extra (2.37-1) ...\n",
            "Setting up fonts-freefont-ttf (20120503-7) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up fonts-go (0~20161116-1) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up fonts-sil-gentium (20081126:1.03-2) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up fonts-sil-gentium-basic (1.102-1) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-gfs-olga (1.1-5) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up fonts-roboto-hinted (2:0~20160106-2) ...\n",
            "Setting up fonts-lobstertwo (2.0-2) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.16) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-fonts-extra-links (2017.20180305-2) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-fonts-extra (2017.20180305-2) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.12) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.12) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otc4Ap7qFMlf"
      },
      "source": [
        "Pip modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srpq4aQNoQ1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b6d7ae-c908-499f-a083-fd77a44f3952"
      },
      "source": [
        "!pip install tensorflow-gpu pyDOE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 5.8 kB/s \n",
            "\u001b[?25hCollecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Collecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 54.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.26.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.47.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 63.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Collecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyDOE) (1.7.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18184 sha256=a6dcbc2090c451d8fdf440a002b4985bd6f20c5e9dd49e5047105ae46402c8b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/ce/8a/87b25c685bfeca1872d13b8dc101e087a9c6e3fb5ebb47022a\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, gast, flatbuffers, tensorflow-gpu, pyDOE\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires keras<2.9,>=2.8.0rc0, but you have keras 2.9.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorboard<2.9,>=2.8, but you have tensorboard 2.9.1 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220719082949 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 2.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-2.9.0 pyDOE-0.3.8 tensorboard-2.9.1 tensorflow-estimator-2.9.0 tensorflow-gpu-2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKujMvUFRNW"
      },
      "source": [
        "## Imports, config, and utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEDn2fqlqctT",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Manually making sure the numpy random seeds are \"the same\" on all devices\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODGREPvZpqUz"
      },
      "source": [
        "burgersutil.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgPvqJiYFnYG",
        "lines_to_next_cell": 0
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pyDOE import lhs\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
        "repoPath = os.path.join(\".\", \"PINNs\")\n",
        "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
        "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
        "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
        "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")\n",
        "\n",
        "sys.path.insert(0, utilsPath)\n",
        "from plotting import newfig, savefig\n",
        "\n",
        "def prep_data(path, N_u=None, N_f=None, N_n=None, q=None, ub=None, lb=None, noise=0.0, idx_t_0=None, idx_t_1=None, N_0=None, N_1=None):\n",
        "    # Reading external data [t is 100x1, usol is 256x100 (solution), x is 256x1]\n",
        "    data = scipy.io.loadmat(path)\n",
        "\n",
        "    # Flatten makes [[]] into [], [:,None] makes it a column vector\n",
        "    t = data['t'].flatten()[:,None] # T x 1\n",
        "    x = data['x'].flatten()[:,None] # N x 1\n",
        "\n",
        "    # Keeping the 2D data for the solution data (real() is maybe to make it float by default, in case of zeroes)\n",
        "    Exact_u = np.real(data['usol']).T # T x N\n",
        "\n",
        "    if N_n != None and q != None and ub != None and lb != None and idx_t_0 != None and idx_t_1 != None:\n",
        "      dt = t[idx_t_1] - t[idx_t_0]\n",
        "      idx_x = np.random.choice(Exact_u.shape[1], N_n, replace=False) \n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_t_0:idx_t_0+1,idx_x].T\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "        \n",
        "      # Boudanry data\n",
        "      x_1 = np.vstack((lb, ub))\n",
        "      \n",
        "      # Test data\n",
        "      x_star = x\n",
        "      u_star = Exact_u[idx_t_1,:]\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
        "      IRK_times = tmp[q**2+q:]\n",
        "\n",
        "      return x, t, dt, Exact_u, x_0, u_0, x_1, x_star, u_star, IRK_weights, IRK_times\n",
        "\n",
        "    # Meshing x and t in 2D (256,100)\n",
        "    X, T = np.meshgrid(x,t)\n",
        "\n",
        "    # Preparing the inputs x and t (meshed as X, T) for predictions in one single array, as X_star\n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "\n",
        "    # Preparing the testing u_star\n",
        "    u_star = Exact_u.flatten()[:,None]\n",
        "                \n",
        "    # Noiseless data TODO: add support for noisy data    \n",
        "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "    X_u_train = X_star[idx,:]\n",
        "    u_train = u_star[idx,:]\n",
        "\n",
        "    if N_0 != None and N_1 != None:\n",
        "      Exact_u = Exact_u.T\n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_0, replace=False)\n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_x,idx_t_0][:,None]\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "          \n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_1, replace=False)\n",
        "      x_1 = x[idx_x,:]\n",
        "      u_1 = Exact_u[idx_x,idx_t_1][:,None]\n",
        "      u_1 = u_1 + noise*np.std(u_1)*np.random.randn(u_1.shape[0], u_1.shape[1])\n",
        "      \n",
        "      dt = np.asscalar(t[idx_t_1] - t[idx_t_0])        \n",
        "      q = int(np.ceil(0.5*np.log(np.finfo(float).eps)/np.log(dt)))\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
        "      IRK_alpha = weights[0:-1,:]\n",
        "      IRK_beta = weights[-1:,:] \n",
        "      return x_0, u_0, x_1, u_1, x, t, dt, q, Exact_u, IRK_alpha, IRK_beta\n",
        "\n",
        "    if N_f == None:\n",
        "      lb = X_star.min(axis=0)\n",
        "      ub = X_star.max(axis=0) \n",
        "      return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, ub, lb\n",
        "\n",
        "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
        "    lb = X_star.min(axis=0)\n",
        "    ub = X_star.max(axis=0) \n",
        "    # Getting the initial conditions (t=0)\n",
        "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
        "    uu1 = Exact_u[0:1,:].T\n",
        "    # Getting the lowest boundary conditions (x=-1) \n",
        "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
        "    uu2 = Exact_u[:,0:1]\n",
        "    # Getting the highest boundary conditions (x=1) \n",
        "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
        "    uu3 = Exact_u[:,-1:]\n",
        "    # Stacking them in multidimensional tensors for training (X_u_train is for now the continuous boundaries)\n",
        "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "    u_train = np.vstack([uu1, uu2, uu3])\n",
        "\n",
        "    # Generating the x and t collocation points for f, with each having a N_f size\n",
        "    # We pointwise add and multiply to spread the LHS over the 2D domain\n",
        "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
        "\n",
        "    # Generating a uniform random sample from ints between 0, and the size of x_u_train, of size N_u (initial data size) and without replacement (unique)\n",
        "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
        "    # Getting the corresponding X_u_train (which is now scarce boundary/initial coordinates)\n",
        "    X_u_train = X_u_train[idx,:]\n",
        "    # Getting the corresponding u_train\n",
        "    u_train = u_train [idx,:]\n",
        "\n",
        "    return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, X_f_train, ub, lb\n",
        "\n",
        "class Logger(object):\n",
        "  def __init__(self, frequency=10):\n",
        "    print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "    print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "    print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
        "\n",
        "    self.start_time = time.time()\n",
        "    self.frequency = frequency\n",
        "\n",
        "  def __get_elapsed(self):\n",
        "    return datetime.fromtimestamp(time.time() - self.start_time).strftime(\"%M:%S\")\n",
        "\n",
        "  def __get_error_u(self):\n",
        "    return self.error_fn()\n",
        "\n",
        "  def set_error_fn(self, error_fn):\n",
        "    self.error_fn = error_fn\n",
        "  \n",
        "  def log_train_start(self, model):\n",
        "    print(\"\\nTraining started\")\n",
        "    print(\"================\")\n",
        "    self.model = model\n",
        "    print(self.model.summary())\n",
        "\n",
        "  def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
        "    if epoch % self.frequency == 0:\n",
        "      print(f\"{'nt_epoch' if is_iter else 'tf_epoch'} = {epoch:6d}  elapsed = {self.__get_elapsed()}  loss = {loss:.4e}  error = {self.__get_error_u():.4e}  \" + custom)\n",
        "\n",
        "  def log_train_opt(self, name):\n",
        "    # print(f\"tf_epoch =      0  elapsed = 00:00  loss = 2.7391e-01  error = 9.0843e-01\")\n",
        "    print(f\"—— Starting {name} optimization ——\")\n",
        "\n",
        "  def log_train_end(self, epoch, custom=\"\"):\n",
        "    print(\"==================\")\n",
        "    print(f\"Training finished (epoch {epoch}): duration = {self.__get_elapsed()}  error = {self.__get_error_u():.4e}  \" + custom)\n",
        "\n",
        "def plot_inf_cont_results(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, file=None):\n",
        "\n",
        "  # Interpolating the results on the whole (x,t) domain.\n",
        "  # griddata(points, values, points at which to interpolate, method)\n",
        "  U_pred = griddata(X_star, u_pred, (X, T), method='cubic')\n",
        "\n",
        "  # Creating the figures\n",
        "  fig, ax = newfig(1.0, 1.1)\n",
        "  ax.axis('off')\n",
        "\n",
        "  ####### Row 0: u(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "\n",
        "  h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "\n",
        "  ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
        "\n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
        "\n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "\n",
        "  ####### Row 1: u(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 3)\n",
        "  gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "  ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 2])\n",
        "  ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])    \n",
        "  ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  if file != None:\n",
        "    savefig(file)\n",
        "\n",
        "def plot_inf_disc_results(x_star, idx_t_0, idx_t_1, x_0, u_0, ub, lb, u_1_pred, Exact_u, x, t, file=None):\n",
        "  fig, ax = newfig(1.0, 1.2)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  ####### Row 0: h(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/2 + 0.1, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "  \n",
        "  h = ax.imshow(Exact_u.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x_star.min(), x_star.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "      \n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  leg = ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  \n",
        "  ####### Row 1: h(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/2-0.05, bottom=0.15, left=0.15, right=0.85, wspace=0.5)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[idx_t_0,:], 'b-', linewidth = 2) \n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_0]), fontsize = 10)\n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.8, -0.3), ncol=2, frameon=False)\n",
        "\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x, Exact_u[idx_t_1,:], 'b-', linewidth = 2, label = 'Exact') \n",
        "  ax.plot(x_star, u_1_pred, 'r--', linewidth = 2, label = 'Prediction')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_1]), fontsize = 10)    \n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  \n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.1, -0.3), ncol=2, frameon=False)\n",
        "    \n",
        "  plt.show()\n",
        "\n",
        "  if file != None:\n",
        "    savefig(file)\n",
        "\n",
        "\n",
        "def plot_ide_disc_results(x_star, t_star, idx_t_0, idx_t_1, x_0, u_0, x_1, u_1,\n",
        "  ub, lb, u_1_pred, Exact, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy,\n",
        "  x, t, file=None):  \n",
        "  fig, ax = newfig(1.0, 1.5)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3+0.05, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "      \n",
        "  h = ax.imshow(Exact, interpolation='nearest', cmap='rainbow',\n",
        "                extent=[t_star.min(),t_star.max(), lb[0], ub[0]],\n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "  \n",
        "  line = np.linspace(x_star.min(), x_star.max(), 2)[:,None]\n",
        "  ax.plot(t_star[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1.0)\n",
        "  ax.plot(t_star[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1.0)    \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/3-0.1, bottom=1-2/3, left=0.15, right=0.85, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x_star,Exact[:,idx_t_0][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_0], u_0.shape[0]), fontsize = 10)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x_star,Exact[:,idx_t_1][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_1, u_1, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_1], u_1.shape[0]), fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(-0.3, -0.3), ncol=2, frameon=False)\n",
        "  \n",
        "  gs2 = gridspec.GridSpec(1, 2)\n",
        "  gs2.update(top=1-2/3-0.05, bottom=0, left=0.15, right=0.85, wspace=0.0)\n",
        "  \n",
        "  ax = plt.subplot(gs2[0, 0])\n",
        "  ax.axis('off')\n",
        "  nu = 0.01/np.pi\n",
        "  s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x + %.6f u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & ' % (nu)\n",
        "  s2 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "  s3 = r'Identified PDE (1\\% noise) & '\n",
        "  s4 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "  s5 = r'\\end{tabular}$'\n",
        "  s = s1+s2+s3+s4+s5\n",
        "  ax.text(-0.1,0.2,s)\n",
        "  plt.show()\n",
        "\n",
        "def plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "  Exact_u, X, T, x, t, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy):\n",
        "    fig, ax = newfig(1.0, 1.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "    \n",
        "    ####### Row 0: u(t,x) ##################    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-1.0/3.0+0.06, left=0.15, right=0.85, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "    #h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "    #              extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "    #              origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 2, clip_on = False)\n",
        "    \n",
        "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ax.set_xlabel('$t$')\n",
        "    ax.set_ylabel('$x$')\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(1.0, -0.125), ncol=5, frameon=False)\n",
        "    ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 1: u(t,x) slices ##################    \n",
        "    gs1 = gridspec.GridSpec(1, 3)\n",
        "    gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 0])\n",
        "    ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')\n",
        "    ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')    \n",
        "    ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 1])\n",
        "    ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 2])\n",
        "    ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])    \n",
        "    ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 3: Identified PDE ##################    \n",
        "    gs2 = gridspec.GridSpec(1, 3)\n",
        "    gs2.update(top=1.0-2.0/3.0, bottom=0, left=0.0, right=1.0, wspace=0.0)\n",
        "    \n",
        "    ax = plt.subplot(gs2[:, :])\n",
        "    ax.axis('off')\n",
        "    s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x - 0.0031831 u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "    s2 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "    s3 = r'Identified PDE (1\\% noise) & '\n",
        "    s4 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s5 = r'\\end{tabular}$'\n",
        "    s = s1+s2+s3+s4+s5\n",
        "    ax.text(0.1,0.1,s)\n",
        "    plt.show()\n",
        "    # savefig('./figures/Burgers_identification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7Azv7DZp0M-"
      },
      "source": [
        "custom_lbfgs.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjvMe1Avpvh9",
        "lines_to_next_cell": 0
      },
      "source": [
        "# Adapted from https://github.com/yaroslavvb/stuff/blob/master/eager_lbfgs/eager_lbfgs.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Time tracking functions\n",
        "global_time_list = []\n",
        "global_last_time = 0\n",
        "def reset_time():\n",
        "  global global_time_list, global_last_time\n",
        "  global_time_list = []\n",
        "  global_last_time = time.perf_counter()\n",
        "  \n",
        "def record_time():\n",
        "  global global_last_time, global_time_list\n",
        "  new_time = time.perf_counter()\n",
        "  global_time_list.append(new_time - global_last_time)\n",
        "  global_last_time = time.perf_counter()\n",
        "  #print(\"step: %.2f\"%(global_time_list[-1]*1000))\n",
        "\n",
        "def last_time():\n",
        "  \"\"\"Returns last interval records in millis.\"\"\"\n",
        "  global global_last_time, global_time_list\n",
        "  if global_time_list:\n",
        "    return 1000 * global_time_list[-1]\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def dot(a, b):\n",
        "  \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
        "  return tf.reduce_sum(a*b)\n",
        "\n",
        "def verbose_func(s):\n",
        "  print(s)\n",
        "\n",
        "final_loss = None\n",
        "times = []\n",
        "def lbfgs(opfunc, x, config, state, do_verbose, log_fn):\n",
        "  \"\"\"port of lbfgs.lua, using TensorFlow eager mode.\n",
        "  \"\"\"\n",
        "\n",
        "  if config.maxIter == 0:\n",
        "    return\n",
        "\n",
        "  global final_loss, times\n",
        "  \n",
        "  maxIter = config.maxIter\n",
        "  maxEval = config.maxEval or maxIter*1.25\n",
        "  tolFun = config.tolFun or 1e-5\n",
        "  tolX = config.tolX or 1e-19\n",
        "  nCorrection = config.nCorrection or 100\n",
        "  lineSearch = config.lineSearch\n",
        "  lineSearchOpts = config.lineSearchOptions\n",
        "  learningRate = config.learningRate or 1\n",
        "  isverbose = config.verbose or False\n",
        "\n",
        "  # verbose function\n",
        "  if isverbose:\n",
        "    verbose = verbose_func\n",
        "  else:\n",
        "    verbose = lambda x: None\n",
        "\n",
        "    # evaluate initial f(x) and df/dx\n",
        "  f, g = opfunc(x)\n",
        "\n",
        "  f_hist = [f]\n",
        "  currentFuncEval = 1\n",
        "  state.funcEval = state.funcEval + 1\n",
        "  p = g.shape[0]\n",
        "\n",
        "  # check optimality of initial point\n",
        "  tmp1 = tf.abs(g)\n",
        "  if tf.reduce_sum(tmp1) <= tolFun:\n",
        "    verbose(\"optimality condition below tolFun\")\n",
        "    return x, f_hist\n",
        "\n",
        "  # optimize for a max of maxIter iterations\n",
        "  nIter = 0\n",
        "  times = []\n",
        "  while nIter < maxIter:\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # keep track of nb of iterations\n",
        "    nIter = nIter + 1\n",
        "    state.nIter = state.nIter + 1\n",
        "\n",
        "    ############################################################\n",
        "    ## compute gradient descent direction\n",
        "    ############################################################\n",
        "    if state.nIter == 1:\n",
        "      d = -g\n",
        "      old_dirs = []\n",
        "      old_stps = []\n",
        "      Hdiag = 1\n",
        "    else:\n",
        "      # do lbfgs update (update memory)\n",
        "      y = g - g_old\n",
        "      s = d*t\n",
        "      ys = dot(y, s)\n",
        "      \n",
        "      if ys > 1e-10:\n",
        "        # updating memory\n",
        "        if len(old_dirs) == nCorrection:\n",
        "          # shift history by one (limited-memory)\n",
        "          del old_dirs[0]\n",
        "          del old_stps[0]\n",
        "\n",
        "        # store new direction/step\n",
        "        old_dirs.append(s)\n",
        "        old_stps.append(y)\n",
        "\n",
        "        # update scale of initial Hessian approximation\n",
        "        Hdiag = ys/dot(y, y)\n",
        "\n",
        "      # compute the approximate (L-BFGS) inverse Hessian \n",
        "      # multiplied by the gradient\n",
        "      k = len(old_dirs)\n",
        "\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      ro = [0]*nCorrection\n",
        "      for i in range(k):\n",
        "        ro[i] = 1/dot(old_stps[i], old_dirs[i])\n",
        "        \n",
        "\n",
        "      # iteration in L-BFGS loop collapsed to use just one buffer\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      al = [0]*nCorrection\n",
        "\n",
        "      q = -g\n",
        "      for i in range(k-1, -1, -1):\n",
        "        al[i] = dot(old_dirs[i], q) * ro[i]\n",
        "        q = q - al[i]*old_stps[i]\n",
        "\n",
        "      # multiply by initial Hessian\n",
        "      r = q*Hdiag\n",
        "      for i in range(k):\n",
        "        be_i = dot(old_stps[i], r) * ro[i]\n",
        "        r += (al[i]-be_i)*old_dirs[i]\n",
        "        \n",
        "      d = r\n",
        "      # final direction is in r/d (same object)\n",
        "\n",
        "    g_old = g\n",
        "    f_old = f\n",
        "    \n",
        "    ############################################################\n",
        "    ## compute step length\n",
        "    ############################################################\n",
        "    # directional derivative\n",
        "    gtd = dot(g, d)\n",
        "\n",
        "    # check that progress can be made along that direction\n",
        "    if gtd > -tolX:\n",
        "      verbose(\"Can not make progress along direction.\")\n",
        "      break\n",
        "\n",
        "    # reset initial guess for step size\n",
        "    if state.nIter == 1:\n",
        "      tmp1 = tf.abs(g)\n",
        "      t = min(1, 1/tf.reduce_sum(tmp1))\n",
        "    else:\n",
        "      t = learningRate\n",
        "\n",
        "\n",
        "    # optional line search: user function\n",
        "    lsFuncEval = 0\n",
        "    if lineSearch and isinstance(lineSearch) == types.FunctionType:\n",
        "      # perform line search, using user function\n",
        "      f,g,x,t,lsFuncEval = lineSearch(opfunc,x,t,d,f,g,gtd,lineSearchOpts)\n",
        "      f_hist.append(f)\n",
        "    else:\n",
        "      # no line search, simply move with fixed-step\n",
        "      x += t*d\n",
        "      \n",
        "      if nIter != maxIter:\n",
        "        # re-evaluate function only if not in last iteration\n",
        "        # the reason we do this: in a stochastic setting,\n",
        "        # no use to re-evaluate that function here\n",
        "        f, g = opfunc(x)\n",
        "        lsFuncEval = 1\n",
        "        f_hist.append(f)\n",
        "\n",
        "\n",
        "    # update func eval\n",
        "    currentFuncEval = currentFuncEval + lsFuncEval\n",
        "    state.funcEval = state.funcEval + lsFuncEval\n",
        "\n",
        "    ############################################################\n",
        "    ## check conditions\n",
        "    ############################################################\n",
        "    if nIter == maxIter:\n",
        "      break\n",
        "\n",
        "    if currentFuncEval >= maxEval:\n",
        "      # max nb of function evals\n",
        "      verbose('max nb of function evals')\n",
        "      break\n",
        "\n",
        "    tmp1 = tf.abs(g)\n",
        "    if tf.reduce_sum(tmp1) <=tolFun:\n",
        "      # check optimality\n",
        "      verbose('optimality condition below tolFun')\n",
        "      break\n",
        "    \n",
        "    tmp1 = tf.abs(d*t)\n",
        "    if tf.reduce_sum(tmp1) <= tolX:\n",
        "      # step size below tolX\n",
        "      verbose('step size below tolX')\n",
        "      break\n",
        "\n",
        "    if tf.abs(f-f_old) < tolX:\n",
        "      # function value changing less than tolX\n",
        "      verbose('function value changing less than tolX'+str(tf.abs(f-f_old)))\n",
        "      break\n",
        "\n",
        "    if do_verbose:\n",
        "      log_fn(nIter, f.numpy(), True)\n",
        "      #print(\"Step %3d loss %6.5f msec %6.3f\"%(nIter, f.numpy(), last_time()))\n",
        "      record_time()\n",
        "      times.append(last_time())\n",
        "\n",
        "    if nIter == maxIter - 1:\n",
        "      final_loss = f.numpy()\n",
        "\n",
        "\n",
        "  # save state\n",
        "  state.old_dirs = old_dirs\n",
        "  state.old_stps = old_stps\n",
        "  state.Hdiag = Hdiag\n",
        "  state.g_old = g_old\n",
        "  state.f_old = f_old\n",
        "  state.t = t\n",
        "  state.d = d\n",
        "\n",
        "  return x, f_hist, currentFuncEval\n",
        "\n",
        "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
        "class dummy(object):\n",
        "  pass\n",
        "\n",
        "class Struct(dummy):\n",
        "  def __getattribute__(self, key):\n",
        "    if key == '__dict__':\n",
        "      return super(dummy, self).__getattribute__('__dict__')\n",
        "    return self.__dict__.get(key, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOT-E8C4oAJN"
      },
      "source": [
        "# 1. Continuous Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Qrt3ECzcLHp"
      },
      "source": [
        "$$u_t + u u_x - \\nu u_{xx} = 0$$\n",
        "\n",
        "With $x \\in [-1,1],\\quad t \\in [0,1],\\quad \\nu = (0.01/\\pi)$.\n",
        "\n",
        "And $u(0,x) = -\\sin(\\pi x),\\quad u(t,-1) = u(t,1) = 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8CHqrpafela"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
        "$$f := u_t + u u_x - \\nu u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_f}|f(t_f^i,x_f^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ and $\\{t_f^i, x_f^i\\}_{i=1}^{N_f}$ respectively the initial/boundary data on $u(t,x)$ and collocations points for $f(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9Ko6L87J2v_"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwWhiecUqbAo",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on the solution u\n",
        "N_u = 50\n",
        "# Collocation points size, where we’ll check for f = 0\n",
        "N_f = 10000\n",
        "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
        "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 100\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  learning_rate=0.1,\n",
        "  beta_1=0.99,\n",
        "  epsilon=1e-1)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 2000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkimJNtepkKi"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3wUjV9oe7V9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVm9UCvvlyY_"
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, X_f, ub, lb, nu):\n",
        "    # Descriptive Keras model [2, 20, …, 20, 1]\n",
        "    self.u_model = tf.keras.Sequential()\n",
        "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.u_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.u_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.nu = nu\n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    # Separating the collocation coordinates\n",
        "    self.x_f = tf.convert_to_tensor(X_f[:, 0:1], dtype=self.dtype)\n",
        "    self.t_f = tf.convert_to_tensor(X_f[:, 1:2], dtype=self.dtype)\n",
        "    \n",
        "  # Defining custom loss\n",
        "  def __loss(self, u, u_pred):\n",
        "    f_pred = self.f_model()\n",
        "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
        "      tf.reduce_mean(tf.square(f_pred))\n",
        "\n",
        "  def __grad(self, X, u):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(u, self.u_model(X))\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.u_model.trainable_variables\n",
        "    return var\n",
        "\n",
        "  # The actual PINN\n",
        "  def f_model(self):\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(self.x_f)\n",
        "      tape.watch(self.t_f)\n",
        "      # Packing together the inputs\n",
        "      X_f = tf.stack([self.x_f[:,0], self.t_f[:,0]], axis=1)\n",
        "\n",
        "      # Getting the prediction\n",
        "      u = self.u_model(X_f)\n",
        "      # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
        "      u_x = tape.gradient(u, self.x_f)\n",
        "    \n",
        "    # Getting the other derivatives\n",
        "    u_xx = tape.gradient(u_x, self.x_f)\n",
        "    u_t = tape.gradient(u, self.t_f)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "\n",
        "    nu = self.get_params(numpy=True)\n",
        "\n",
        "    # Buidling the PINNs\n",
        "    return u_t + u*u_x - nu*u_xx\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    return self.nu\n",
        "\n",
        "  def get_weights(self):\n",
        "    w = []\n",
        "    for layer in self.u_model.layers[1:]:\n",
        "      weights_biases = layer.get_weights()\n",
        "      weights = weights_biases[0].flatten()\n",
        "      biases = weights_biases[1]\n",
        "      w.extend(weights)\n",
        "      w.extend(biases)\n",
        "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "\n",
        "  def summary(self):\n",
        "    return self.u_model.summary()\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, X_u, u, tf_epochs=5000, nt_config=Struct()):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
        "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(X_u, u)\n",
        "      self.optimizer.apply_gradients(zip(grads, self.__wrap_training_variables()))\n",
        "      self.logger.log_train_epoch(epoch, loss_value)\n",
        "    \n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        loss_value = self.__loss(u, self.u_model(X_u))\n",
        "      grad = tape.gradient(loss_value, self.u_model.trainable_variables)\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True,\n",
        "      lambda epoch, loss, is_iter:\n",
        "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\n",
        "\n",
        "    self.logger.log_train_end(tf_epochs + nt_config.maxIter)\n",
        "\n",
        "  def predict(self, X_star):\n",
        "    u_star = self.u_model(X_star)\n",
        "    f_star = self.f_model()\n",
        "    return u_star, f_star"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FzMd65dpoHo"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEKkpHvApf46",
        "lines_to_next_cell": 2,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f8a2aa-df30-4e13-fa55-10aec154fa79"
      },
      "source": [
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "  X_u_train, u_train, X_f, ub, lb = prep_data(path, N_u, N_f, noise=0.0)\n",
        "\n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, X_f, ub, lb, nu=0.01/np.pi)\n",
        "def error():\n",
        "  u_pred, _ = pinn.predict(X_star)\n",
        "  return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_pred, f_pred = pinn.predict(X_star)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.1\n",
            "Eager execution: True\n",
            "WARNING:tensorflow:From <ipython-input-5-88c6aa07427f>:131: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda (Lambda)             (None, 2)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                60        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,021\n",
            "Trainable params: 3,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "—— Starting Adam optimization ——\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "tf_epoch =      0  elapsed = 00:02  loss = 2.9103e-01  error = 8.8958e-01  \n",
            "tf_epoch =     10  elapsed = 00:03  loss = 2.1053e-01  error = 7.8298e-01  \n",
            "tf_epoch =     20  elapsed = 00:05  loss = 1.8826e-01  error = 6.7527e-01  \n",
            "tf_epoch =     30  elapsed = 00:06  loss = 1.6335e-01  error = 6.6386e-01  \n",
            "tf_epoch =     40  elapsed = 00:07  loss = 1.5234e-01  error = 6.1549e-01  \n",
            "tf_epoch =     50  elapsed = 00:08  loss = 1.5271e-01  error = 5.5059e-01  \n",
            "tf_epoch =     60  elapsed = 00:10  loss = 1.5121e-01  error = 6.1824e-01  \n",
            "tf_epoch =     70  elapsed = 00:11  loss = 1.4983e-01  error = 5.9295e-01  \n",
            "tf_epoch =     80  elapsed = 00:12  loss = 1.4985e-01  error = 6.3547e-01  \n",
            "tf_epoch =     90  elapsed = 00:14  loss = 1.4213e-01  error = 5.9022e-01  \n",
            "—— Starting LBFGS optimization ——\n",
            "nt_epoch =     10  elapsed = 00:17  loss = 1.0505e-01  error = 5.0906e-01  \n",
            "nt_epoch =     20  elapsed = 00:19  loss = 8.8612e-02  error = 5.1689e-01  \n",
            "nt_epoch =     30  elapsed = 00:21  loss = 7.3399e-02  error = 4.9323e-01  \n",
            "nt_epoch =     40  elapsed = 00:23  loss = 6.4590e-02  error = 4.6721e-01  \n",
            "nt_epoch =     50  elapsed = 00:23  loss = 6.1805e-02  error = 4.5981e-01  \n",
            "nt_epoch =     60  elapsed = 00:24  loss = 5.7593e-02  error = 4.4954e-01  \n",
            "nt_epoch =     70  elapsed = 00:26  loss = 5.4635e-02  error = 4.4226e-01  \n",
            "nt_epoch =     80  elapsed = 00:27  loss = 4.9311e-02  error = 4.2250e-01  \n",
            "nt_epoch =     90  elapsed = 00:28  loss = 4.4712e-02  error = 3.8744e-01  \n",
            "nt_epoch =    100  elapsed = 00:29  loss = 4.0963e-02  error = 3.6294e-01  \n",
            "==================\n",
            "Training finished (epoch 2100): duration = 00:29  error = 1.9818e+00  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_star.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A5mUrwivvlB",
        "outputId": "81e95e3d-1677-4732-e6e2-aa52a7107b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25600, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXslWmylv6Ga",
        "outputId": "29560968-bca4-41e2-8141-5e5733afe1d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([25600, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf1QXaK5PlUh",
        "lines_to_next_cell": 0,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dcd052e-03ba-43af-c663-c52db4172fe5"
      },
      "source": [
        "plot_inf_cont_results(X_star, u_pred, X_u_train, u_train,Exact_u, X, T, x, t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-051159fb108a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_inf_cont_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_u_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mExact_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-88c6aa07427f>\u001b[0m in \u001b[0;36mplot_inf_cont_results\u001b[0;34m(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, file)\u001b[0m\n\u001b[1;32m    178\u001b[0m   h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n\u001b[1;32m    179\u001b[0m                 \u001b[0mextent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 origin='lower', aspect='auto')\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0mdivider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_axes_locatable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m   \u001b[0mcax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"right\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"5%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 256, 100) for image data"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <function install_repl_displayhook.<locals>.post_execute at 0x7fccee717710> (for post_execute):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    305\u001b[0m                                              \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                                              stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['latex', '-interaction=nonstopmode', '--halt-on-error', '/root/.cache/matplotlib/tex.cache/845f8a8cdff43e20ba665c5e0c349657.tex']' returned non-zero exit status 1.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/_pylab_helpers.py\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1229\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size_in_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             w, h, d = texmanager.get_text_width_height_descent(\n\u001b[0;32m--> 204\u001b[0;31m                 s, fontsize, renderer=self)\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# use dviread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mdvifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpi_fraction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mmake_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._run_checked_subprocess(\n\u001b[1;32m    339\u001b[0m                     [\"latex\", \"-interaction=nonstopmode\", \"--halt-on-error\",\n\u001b[0;32m--> 340\u001b[0;31m                      texfile], tex)\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dvi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mtex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode_escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     exc=exc.output.decode('utf-8'))) from exc\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: latex was not able to process the following string:\nb'lp'\n\nHere is the full report generated by latex:\nThis is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017/Debian) (preloaded format=latex)\n restricted \\write18 enabled.\nentering extended mode\n(/root/.cache/matplotlib/tex.cache/845f8a8cdff43e20ba665c5e0c349657.tex\nLaTeX2e <2017-04-15>\nBabel <3.18> and hyphenation patterns for 3 language(s) loaded.\n(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2014/09/29 v1.4h Standard LaTeX document class\n(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo))\n(/usr/share/texlive/texmf-dist/tex/latex/type1cm/type1cm.sty)\n\n! LaTeX Error: File `type1ec.sty' not found.\n\nType X to quit or <RETURN> to proceed,\nor enter new name. (Default extension: sty)\n\nEnter file name: \n! Emergency stop.\n<read *> \n         \nl.8 \\usepackage\n               {textcomp}^^M\nNo pages of output.\nTranscript written on 845f8a8cdff43e20ba665c5e0c349657.log.\n\n\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    305\u001b[0m                                              \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                                              stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['latex', '-interaction=nonstopmode', '--halt-on-error', '/root/.cache/matplotlib/tex.cache/845f8a8cdff43e20ba665c5e0c349657.tex']' returned non-zero exit status 1.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1229\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get window extent w/o renderer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    291\u001b[0m         _, lp_h, lp_d = renderer.get_text_width_height_descent(\n\u001b[1;32m    292\u001b[0m             \u001b[0;34m\"lp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fontproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             ismath=\"TeX\" if self.get_usetex() else False)\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mmin_dy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlp_h\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlp_d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_linespacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, s, prop, ismath)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_size_in_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             w, h, d = texmanager.get_text_width_height_descent(\n\u001b[0;32m--> 204\u001b[0;31m                 s, fontsize, renderer=self)\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mget_text_width_height_descent\u001b[0;34m(self, tex, fontsize, renderer)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# use dviread.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mdvifile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mdviread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdvifile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdpi_fraction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdvi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36mmake_dvi\u001b[0;34m(self, tex, fontsize)\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._run_checked_subprocess(\n\u001b[1;32m    339\u001b[0m                     [\"latex\", \"-interaction=nonstopmode\", \"--halt-on-error\",\n\u001b[0;32m--> 340\u001b[0;31m                      texfile], tex)\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasefile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dvi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/texmanager.py\u001b[0m in \u001b[0;36m_run_checked_subprocess\u001b[0;34m(self, command, tex)\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mtex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unicode_escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     exc=exc.output.decode('utf-8'))) from exc\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: latex was not able to process the following string:\nb'lp'\n\nHere is the full report generated by latex:\nThis is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017/Debian) (preloaded format=latex)\n restricted \\write18 enabled.\nentering extended mode\n(/root/.cache/matplotlib/tex.cache/845f8a8cdff43e20ba665c5e0c349657.tex\nLaTeX2e <2017-04-15>\nBabel <3.18> and hyphenation patterns for 3 language(s) loaded.\n(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\nDocument Class: article 2014/09/29 v1.4h Standard LaTeX document class\n(/usr/share/texlive/texmf-dist/tex/latex/base/size10.clo))\n(/usr/share/texlive/texmf-dist/tex/latex/type1cm/type1cm.sty)\n\n! LaTeX Error: File `type1ec.sty' not found.\n\nType X to quit or <RETURN> to proceed,\nor enter new name. (Default extension: sty)\n\nEnter file name: \n! Emergency stop.\n<read *> \n         \nl.8 \\usepackage\n               {textcomp}^^M\nNo pages of output.\nTranscript written on 845f8a8cdff43e20ba665c5e0c349657.log.\n\n\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 388.543x264.146 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-Dt42ItxAqr"
      },
      "source": [
        "# 2. Discrete Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1oPFjYDxAqs"
      },
      "source": [
        "$$u_t + u u_x - \\nu u_{xx} = 0$$\n",
        "\n",
        "With $x \\in [-1,1],\\quad t \\in [0,1],\\quad \\nu = (0.01/\\pi)$.\n",
        "\n",
        "And $u(0,x) = -\\sin(\\pi x),\\quad u(t,-1) = u(t,1) = 0$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4z7cQz_xAqt"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN: (TODO)\n",
        "$$f := u_t + u u_x - \\nu u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss: (TODO)\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_f}|f(t_f^i,x_f^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ and $\\{t_f^i, x_f^i\\}_{i=1}^{N_f}$ respectively the initial/boundary data on $u(t,x)$ and collocations points for $f(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGd5zVtoxAqt"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKrkV1ChxAqu",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on initial condition on u\n",
        "N_n = 250\n",
        "# Number of RK stages\n",
        "q = 500\n",
        "# DeepNN topology (1-sized input [x], 3 hidden layer of 50-width, q+1-sized output [u_1^n(x), ..., u_{q+1}^n(x)]\n",
        "layers = [1, 50, 50, 50, q + 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 200\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  lr=0.001,\n",
        "  beta_1=0.9,\n",
        "  beta_2=0.999,\n",
        "  epsilon=1e-08)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 1000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtJ5GiaxAqw"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiPSoTyPxAqw"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2acHqmorxAqx"
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, dt, x_1, lb, ub, nu, q, IRK_weights, IRK_times):\n",
        "    self.lb = lb\n",
        "    self.ub = ub\n",
        "    self.nu = nu\n",
        "\n",
        "    self.dt = dt\n",
        "\n",
        "    self.q = max(q,1)\n",
        "    self.IRK_weights = IRK_weights\n",
        "    self.IRK_times = IRK_times\n",
        "\n",
        "    # Descriptive Keras model [2, 50, …, 50, q+1]\n",
        "    self.U_1_model = tf.keras.Sequential()\n",
        "    self.U_1_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.U_1_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.U_1_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    self.x_1 = tf.convert_to_tensor(x_1, dtype=self.dtype)\n",
        "\n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "  def U_0_model(self, x):\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(x)\n",
        "      tape.watch(self.dummy_x0_tf)\n",
        "\n",
        "      # Getting the prediction, and removing the last item (q+1)\n",
        "      U_1 = self.U_1_model(x) # shape=(len(x), q+1)\n",
        "      U = U_1[:, :-1] # shape=(len(x), q)\n",
        "\n",
        "      # Deriving INSIDE the tape (2-step-dummy grad technique because U is a mat)\n",
        "      g_U = tape.gradient(U, x, output_gradients=self.dummy_x0_tf)\n",
        "      U_x = tape.gradient(g_U, self.dummy_x0_tf)\n",
        "      g_U_x = tape.gradient(U_x, x, output_gradients=self.dummy_x0_tf)\n",
        "    \n",
        "    # Doing the last one outside the with, to optimize performance\n",
        "    # Impossible to do for the earlier grad, because they’re needed after\n",
        "    U_xx = tape.gradient(g_U_x, self.dummy_x0_tf)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "\n",
        "    # Buidling the PINNs, shape = (len(x), q+1), IRK shape = (q, q+1)\n",
        "    nu = self.get_params(numpy=True)\n",
        "    N = U*U_x - nu*U_xx # shape=(len(x), q)\n",
        "    return U_1 + self.dt*tf.matmul(N, self.IRK_weights.T)\n",
        "\n",
        "  # Defining custom loss\n",
        "  def __loss(self, u_0, u_0_pred):\n",
        "    u_1_pred = self.U_1_model(self.x_1)\n",
        "    return tf.reduce_sum(tf.square(u_0_pred - u_0)) + \\\n",
        "      tf.reduce_sum(tf.square(u_1_pred))\n",
        "\n",
        "  def __grad(self, x_0, u_0):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(u_0, self.U_0_model(x_0))\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.U_1_model.trainable_variables\n",
        "    return var\n",
        "\n",
        "  def get_weights(self):\n",
        "    w = []\n",
        "    for layer in self.U_1_model.layers[1:]:\n",
        "      weights_biases = layer.get_weights()\n",
        "      weights = weights_biases[0].flatten()\n",
        "      biases = weights_biases[1]\n",
        "      w.extend(weights)\n",
        "      w.extend(biases)\n",
        "    return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.U_1_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    return self.nu\n",
        "\n",
        "  def summary(self):\n",
        "    return self.U_1_model.summary()\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, x_0, u_0, tf_epochs, nt_config):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    x_0 = tf.convert_to_tensor(x_0, dtype=self.dtype)\n",
        "    u_0 = tf.convert_to_tensor(u_0, dtype=self.dtype)\n",
        "\n",
        "    # Creating dummy tensors for the gradients\n",
        "    self.dummy_x0_tf = tf.ones([x_0.shape[0], self.q], dtype=self.dtype)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(x_0, u_0)\n",
        "      self.optimizer.apply_gradients(\n",
        "        zip(grads, self.__wrap_training_variables()))\n",
        "      self.logger.log_train_epoch(epoch, loss_value)\n",
        "\n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        loss_value = self.__loss(u_0, self.U_0_model(x_0))\n",
        "      grad = tape.gradient(loss_value, self.U_1_model.trainable_variables)\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True,\n",
        "      lambda epoch, loss, is_iter:\n",
        "        self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\n",
        "    \n",
        "    self.logger.log_train_end(tf_epochs)\n",
        "\n",
        "  def predict(self, x_star):\n",
        "    u_star = self.U_1_model(x_star)[:, -1]\n",
        "    return u_star"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIq8U_a_xAqy"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ICbcZhxAqz"
      },
      "source": [
        "\n",
        "# Setup\n",
        "lb = np.array([-1.0])\n",
        "ub = np.array([1.0])\n",
        "idx_t_0 = 10\n",
        "idx_t_1 = 90\n",
        "nu = 0.01/np.pi\n",
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x, t, dt, \\\n",
        "  Exact_u, x_0, u_0, x_1, x_star, u_star, \\\n",
        "  IRK_weights, IRK_times = prep_data(path, N_n=N_n, q=q, lb=lb, ub=ub, noise=0.0, idx_t_0=idx_t_0, idx_t_1=idx_t_1)\n",
        "\n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, dt, x_1, lb, ub, nu, q, IRK_weights, IRK_times)\n",
        "def error():\n",
        "  u_pred = pinn.predict(x_star)\n",
        "  return np.linalg.norm(u_pred - u_star, 2) / np.linalg.norm(u_star, 2)\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(x_0, u_0, tf_epochs, nt_config)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_1_pred = pinn.predict(x_star)\n",
        "\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_1_pred = pinn.predict(x_star)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9aFDcGpxAq2",
        "lines_to_next_cell": 0
      },
      "source": [
        "#plot_inf_disc_results(x_star, idx_t_0, idx_t_1, x_0, u_0, ub, lb, u_1_pred, Exact_u, x, t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoN7tCmSGDeO"
      },
      "source": [
        "# 3. Continuous Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkpuORIsGDeQ"
      },
      "source": [
        "$$u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx} = 0$$\n",
        "\n",
        "With $\\lambda_1$ and $\\lambda_2$ real parameters of the differential operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpUoecjeGDeR"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
        "$$f := u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_u}|f(t_u^i,x_u^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ respectively the trainring data on $u(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOPzdkKsJzA4"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKRYhyXqGDeT",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on the solution u\n",
        "N_u = 2000\n",
        "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
        "layers = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 100\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  learning_rate=0.001)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 1000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTxvp1nJGDeb"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9grEA3wGDed"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLOwP1UfGDee",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, ub, lb):\n",
        "    # Descriptive Keras model [2, 20, …, 20, 1]\n",
        "    self.u_model = tf.keras.Sequential()\n",
        "    self.u_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.u_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.u_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    # Defining the two additional trainable variables for identification\n",
        "    self.lambda_1 = tf.Variable([0.0], dtype=self.dtype)\n",
        "    self.lambda_2 = tf.Variable([-6.0], dtype=self.dtype)\n",
        "    \n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "  # The actual PINN\n",
        "  def __f_model(self, X_u):\n",
        "    l1, l2 = self.get_params()\n",
        "    # Separating the collocation coordinates\n",
        "    x_f = tf.convert_to_tensor(X_u[:, 0:1], dtype=self.dtype)\n",
        "    t_f = tf.convert_to_tensor(X_u[:, 1:2], dtype=self.dtype)\n",
        "\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(x_f)\n",
        "      tape.watch(t_f)\n",
        "      # Packing together the inputs\n",
        "      X_f = tf.stack([x_f[:,0], t_f[:,0]], axis=1)\n",
        "\n",
        "\n",
        "      # Getting the prediction\n",
        "      u = self.u_model(X_f)\n",
        "      # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
        "      u_x = tape.gradient(u, x_f)\n",
        "    \n",
        "    # Getting the other derivatives\n",
        "    u_xx = tape.gradient(u_x, x_f)\n",
        "    u_t = tape.gradient(u, t_f)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "\n",
        "    # Buidling the PINNs\n",
        "    return u_t + l1*u*u_x - l2*u_xx\n",
        "\n",
        "  # Defining custom loss\n",
        "  def __loss(self, X_u, u, u_pred):\n",
        "    f_pred = self.__f_model(X_u)\n",
        "    return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
        "      tf.reduce_mean(tf.square(f_pred))\n",
        "\n",
        "  def __grad(self, X, u):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(X, u, self.u_model(X))\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.u_model.trainable_variables\n",
        "    var.extend([self.lambda_1, self.lambda_2])\n",
        "    return var\n",
        "\n",
        "  def get_weights(self):\n",
        "      w = []\n",
        "      for layer in self.u_model.layers[1:]:\n",
        "        weights_biases = layer.get_weights()\n",
        "        weights = weights_biases[0].flatten()\n",
        "        biases = weights_biases[1]\n",
        "        w.extend(weights)\n",
        "        w.extend(biases)\n",
        "      w.extend(self.lambda_1.numpy())\n",
        "      w.extend(self.lambda_2.numpy())\n",
        "      return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.u_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "    self.lambda_1.assign([w[-2]])\n",
        "    self.lambda_2.assign([w[-1]])\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    if numpy:\n",
        "      return l1.numpy()[0], l2.numpy()[0]\n",
        "    return l1, l2\n",
        "\n",
        "  def summary(self):\n",
        "    return self.u_model.summary()\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, X_u, u, tf_epochs, nt_config):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    X_u = tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
        "    u = tf.convert_to_tensor(u, dtype=self.dtype)\n",
        "\n",
        "    def log_train_epoch(epoch, loss, is_iter):\n",
        "      l1, l2 = self.get_params(numpy=True)\n",
        "      custom = f\"l1 = {l1:5f}  l2 = {l2:8f}\"\n",
        "      self.logger.log_train_epoch(epoch, loss, custom, is_iter)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(X_u, u)\n",
        "      self.optimizer.apply_gradients(\n",
        "        zip(grads, self.__wrap_training_variables()))\n",
        "      log_train_epoch(epoch, loss_value, False)\n",
        "\n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        tape.watch(self.lambda_1)\n",
        "        tape.watch(self.lambda_2)\n",
        "        loss_value = self.__loss(X_u, u, self.u_model(X_u))\n",
        "      grad = tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True, log_train_epoch)\n",
        "    \n",
        "    l1, l2 = self.get_params(numpy=True)\n",
        "    self.logger.log_train_end(tf_epochs, f\"l1 = {l1:5f}  l2 = {l2:8f}\")\n",
        "\n",
        "  def predict(self, X_star):\n",
        "    u_star = self.u_model(X_star)\n",
        "    f_star = self.__f_model(X_star)\n",
        "    return u_star.numpy(), f_star.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rWEI708GDei"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxkeBW46GDek",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "  X_u_train, u_train, ub, lb = prep_data(path, N_u, noise=0.0)\n",
        "lambdas_star = (1.0, 0.01/np.pi)\n",
        "\n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, ub, lb)\n",
        "def error():\n",
        "  l1, l2 = pinn.get_params(numpy=True)\n",
        "  l1_star, l2_star = lambdas_star\n",
        "  error_lambda_1 = np.abs(l1 - l1_star) / l1_star\n",
        "  error_lambda_2 = np.abs(l2 - l2_star) / l2_star\n",
        "  return (error_lambda_1 + error_lambda_2) / 2\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_pred, f_pred = pinn.predict(X_star)\n",
        "lambda_1_pred, lambda_2_pred = pinn.get_params(numpy=True)\n",
        "\n",
        "# Noise case\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "  X_u_train, u_train, ub, lb = prep_data(path, N_u, noise=0.01)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, ub, lb)\n",
        "pinn.fit(X_u_train, u_train, tf_epochs, nt_config)\n",
        "lambda_1_pred_noise, lambda_2_pred_noise = pinn.get_params(numpy=True)\n",
        "\n",
        "print(\"l1: \", lambda_1_pred)\n",
        "print(\"l2: \", lambda_2_pred)\n",
        "print(\"l1_noise: \", lambda_1_pred_noise)\n",
        "print(\"l2_noise: \", lambda_2_pred_noise)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-y6mkKpP5M8",
        "lines_to_next_cell": 0
      },
      "source": [
        "#plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "#  Exact_u, X, T, x, t, lambda_1_pred, lambda_1_pred_noise, lambda_2_pred, lambda_2_pred_noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcY8EfT1w1ev"
      },
      "source": [
        "# 4. Discrete Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFBJUhYqw1ew"
      },
      "source": [
        "$$u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx} = 0$$\n",
        "\n",
        "With $\\lambda_1$ and $\\lambda_2$ real parameters of the differential operator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKxgAhrTw1ex"
      },
      "source": [
        "Approximating $u(t,x)$ with a deep NN, we define the PINN:\n",
        "$$f := u_t + \\lambda_1 u u_x - \\lambda_2 u_{xx}.$$\n",
        "\n",
        "We train the shared parameters between the deep NN and the PINN minimizing the loss:\n",
        "$$MSE =\\frac{1}{N_u}\\sum_{i=1}^{N_u} |u(t^i_u,x_u^i) - u^i|^2 + \\frac{1}{N_f}\\sum_{i=1}^{N_u}|f(t_u^i,x_u^i)|^2,$$\n",
        "with $\\{t_u^i, x_u^i, u^i\\}_{i=1}^{N_u}$ respectively the trainring data on $u(t,x)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGrMDRc3w1ex"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOuJ6DV1w1ey",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Data size on initial condition on u\n",
        "N_0 = 199\n",
        "N_1 = 201\n",
        "# DeepNN topology (1-sized input [x], 3 hidden layer of 50-width, q-sized output defined later [u_1^n(x), ..., u_{q+1}^n(x)]\n",
        "layers = [1, 50, 50, 50, 0]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "tf_epochs = 100\n",
        "tf_optimizer = tf.keras.optimizers.Adam(\n",
        "  lr=0.001,\n",
        "  beta_1=0.9,\n",
        "  beta_2=0.999,\n",
        "  epsilon=1e-08)\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "nt_epochs = 2000\n",
        "nt_config = Struct()\n",
        "nt_config.learningRate = 0.8\n",
        "nt_config.maxIter = nt_epochs\n",
        "nt_config.nCorrection = 50\n",
        "nt_config.tolFun = 1.0 * np.finfo(float).eps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRGW4IW0w1e0"
      },
      "source": [
        "## PINN class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYMIf2_Uw1e0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yiB3TOYw1e1"
      },
      "source": [
        "\n",
        "class PhysicsInformedNN(object):\n",
        "  def __init__(self, layers, optimizer, logger, dt, lb, ub, q, IRK_alpha, IRK_beta):\n",
        "    self.lb = lb\n",
        "    self.ub = ub\n",
        "\n",
        "    self.dt = dt\n",
        "\n",
        "    self.q = max(q,1)\n",
        "    self.IRK_alpha = IRK_alpha\n",
        "    self.IRK_beta = IRK_beta\n",
        "\n",
        "    # Descriptive Keras model [2, 50, …, 50, q+1]\n",
        "    self.U_model = tf.keras.Sequential()\n",
        "    self.U_model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "    self.U_model.add(tf.keras.layers.Lambda(\n",
        "      lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "    for width in layers[1:]:\n",
        "        self.U_model.add(tf.keras.layers.Dense(\n",
        "          width, activation=tf.nn.tanh,\n",
        "          kernel_initializer='glorot_normal'))\n",
        "\n",
        "    # Computing the sizes of weights/biases for future decomposition\n",
        "    self.sizes_w = []\n",
        "    self.sizes_b = []\n",
        "    for i, width in enumerate(layers):\n",
        "      if i != 1:\n",
        "        self.sizes_w.append(int(width * layers[1]))\n",
        "        self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "    self.dtype = tf.float32\n",
        "\n",
        "    self.optimizer = optimizer\n",
        "    self.logger = logger\n",
        "\n",
        "  def __autograd(self, U, x, dummy):\n",
        "    # Using the new GradientTape paradigm of TF2.0,\n",
        "    # which keeps track of operations to get the gradient at runtime\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "      # Watching the two inputs we’ll need later, x and t\n",
        "      tape.watch(x)\n",
        "      tape.watch(dummy)\n",
        "\n",
        "      # Getting the prediction\n",
        "      U = self.U_model(x) # shape=(len(x), q)\n",
        "\n",
        "      # Deriving INSIDE the tape (2-step-dummy grad technique because U is a mat)\n",
        "      g_U = tape.gradient(U, x, output_gradients=dummy)\n",
        "      U_x = tape.gradient(g_U, dummy)\n",
        "      g_U_x = tape.gradient(U_x, x, output_gradients=dummy)\n",
        "    \n",
        "    # Doing the last one outside the with, to optimize performance\n",
        "    # Impossible to do for the earlier grad, because they’re needed after\n",
        "    U_xx = tape.gradient(g_U_x, dummy)\n",
        "\n",
        "    # Letting the tape go\n",
        "    del tape\n",
        "    return U_x, U_xx\n",
        "\n",
        "  def U_0_model(self, x, customDummy=None):\n",
        "    U = self.U_model(x)\n",
        "    if customDummy != None:\n",
        "      dummy = customDummy\n",
        "    else:\n",
        "      dummy = self.dummy_x_0\n",
        "    U_x, U_xx = self.__autograd(U, x, dummy)\n",
        "\n",
        "    # Buidling the PINNs\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    N = l1*U*U_x - l2*U_xx # shape=(len(x), q)\n",
        "    return U + self.dt*tf.matmul(N, self.IRK_alpha.T)\n",
        "\n",
        "  def U_1_model(self, x, customDummy=None):\n",
        "    U = self.U_model(x)\n",
        "    #dummy = customDummy or self.dummy_x_1\n",
        "    if customDummy != None:\n",
        "      dummy = customDummy\n",
        "    else:\n",
        "      dummy = self.dummy_x_1\n",
        "    U_x, U_xx = self.__autograd(U, x, dummy)\n",
        "\n",
        "    # Buidling the PINNs, shape = (len(x), q+1), IRK shape = (q, q+1)\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    N = -l1*U*U_x + l2*U_xx # shape=(len(x), q)\n",
        "    return U + self.dt*tf.matmul(N, (self.IRK_beta - self.IRK_alpha).T)\n",
        "\n",
        "  # Defining custom loss\n",
        "  def __loss(self, x_0, u_0, x_1, u_1):\n",
        "    u_0_pred = self.U_0_model(x_0)\n",
        "    u_1_pred = self.U_1_model(x_1)\n",
        "    return tf.reduce_sum(tf.square(u_0_pred - u_0)) + \\\n",
        "      tf.reduce_sum(tf.square(u_1_pred - u_1))\n",
        "\n",
        "  def __grad(self, x_0, u_0, x_1, u_1):\n",
        "    with tf.GradientTape() as tape:\n",
        "      loss_value = self.__loss(x_0, u_0, x_1, u_1)\n",
        "    return loss_value, tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "\n",
        "  def __wrap_training_variables(self):\n",
        "    var = self.U_model.trainable_variables\n",
        "    var.extend([self.lambda_1, self.lambda_2])\n",
        "    return var\n",
        "\n",
        "  def get_weights(self):\n",
        "      w = []\n",
        "      for layer in self.U_model.layers[1:]:\n",
        "        weights_biases = layer.get_weights()\n",
        "        weights = weights_biases[0].flatten()\n",
        "        biases = weights_biases[1]\n",
        "        w.extend(weights)\n",
        "        w.extend(biases)\n",
        "      w.extend(self.lambda_1.numpy())\n",
        "      w.extend(self.lambda_2.numpy())\n",
        "      return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "  def set_weights(self, w):\n",
        "    for i, layer in enumerate(self.U_model.layers[1:]):\n",
        "      start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "      end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "      weights = w[start_weights:end_weights]\n",
        "      w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "      weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "      biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "      weights_biases = [weights, biases]\n",
        "      layer.set_weights(weights_biases)\n",
        "    self.lambda_1.assign([w[-2]])\n",
        "    self.lambda_2.assign([w[-1]])\n",
        "\n",
        "  def get_params(self, numpy=False):\n",
        "    l1 = self.lambda_1\n",
        "    l2 = tf.exp(self.lambda_2)\n",
        "    if numpy:\n",
        "      return l1.numpy()[0], l2.numpy()[0]\n",
        "    return l1, l2\n",
        "\n",
        "  def summary(self):\n",
        "    return self.U_model.summary()\n",
        "\n",
        "  def __createDummy(self, x):\n",
        "    return tf.ones([x.shape[0], self.q], dtype=self.dtype)\n",
        "\n",
        "  # The training function\n",
        "  def fit(self, x_0, u_0, x_1, u_1, tf_epochs=1):\n",
        "    self.logger.log_train_start(self)\n",
        "\n",
        "    # Creating the tensors\n",
        "    x_0 = tf.convert_to_tensor(x_0, dtype=self.dtype)\n",
        "    u_0 = tf.convert_to_tensor(u_0, dtype=self.dtype)\n",
        "    x_1 = tf.convert_to_tensor(x_1, dtype=self.dtype)\n",
        "    u_1 = tf.convert_to_tensor(u_1, dtype=self.dtype)\n",
        "\n",
        "    self.lambda_1 = tf.Variable([0.0], dtype=self.dtype)\n",
        "    self.lambda_2 = tf.Variable([-6.0], dtype=self.dtype)\n",
        "\n",
        "    # Creating dummy tensors for the gradients\n",
        "    self.dummy_x_0 = self.__createDummy(x_0)\n",
        "    self.dummy_x_1 = self.__createDummy(x_1)\n",
        "\n",
        "    def log_train_epoch(epoch, loss, is_iter):\n",
        "      l1, l2 = self.get_params(numpy=True)\n",
        "      custom = f\"l1 = {l1:5f}  l2 = {l2:8f}\"\n",
        "      self.logger.log_train_epoch(epoch, loss, custom, is_iter)\n",
        "\n",
        "    self.logger.log_train_opt(\"Adam\")\n",
        "    for epoch in range(tf_epochs):\n",
        "      # Optimization step\n",
        "      loss_value, grads = self.__grad(x_0, u_0, x_1, u_1)\n",
        "      self.optimizer.apply_gradients(\n",
        "        zip(grads, self.__wrap_training_variables()))\n",
        "      log_train_epoch(epoch, loss_value, False)\n",
        "    \n",
        "    self.logger.log_train_opt(\"LBFGS\")\n",
        "    def loss_and_flat_grad(w):\n",
        "      with tf.GradientTape() as tape:\n",
        "        self.set_weights(w)\n",
        "        tape.watch(self.lambda_1)\n",
        "        tape.watch(self.lambda_2)\n",
        "        loss_value = self.__loss(x_0, u_0, x_1, u_1)\n",
        "      grad = tape.gradient(loss_value, self.__wrap_training_variables())\n",
        "      grad_flat = []\n",
        "      for g in grad:\n",
        "        grad_flat.append(tf.reshape(g, [-1]))\n",
        "      grad_flat =  tf.concat(grad_flat, 0)\n",
        "      return loss_value, grad_flat\n",
        "    # tfp.optimizer.lbfgs_minimize(\n",
        "    #   loss_and_flat_grad,\n",
        "    #   initial_position=self.get_weights(),\n",
        "    #   num_correction_pairs=nt_config.nCorrection,\n",
        "    #   max_iterations=nt_config.maxIter,\n",
        "    #   f_relative_tolerance=nt_config.tolFun,\n",
        "    #   tolerance=nt_config.tolFun,\n",
        "    #   parallel_iterations=6)\n",
        "    lbfgs(loss_and_flat_grad,\n",
        "      self.get_weights(),\n",
        "      nt_config, Struct(), True, log_train_epoch)\n",
        "    \n",
        "    l1, l2 = self.get_params(numpy=True)\n",
        "    self.logger.log_train_end(tf_epochs, f\"l1 = {l1:5f}  l2 = {l2:8f}\")\n",
        "\n",
        "  def predict(self, x_star):\n",
        "    x_star = tf.convert_to_tensor(x_star, dtype=self.dtype)\n",
        "    dummy = self.__createDummy(x_star)\n",
        "    U_0_star = self.U_0_model(x_star, dummy)\n",
        "    U_1_star = self.U_1_model(x_star, dummy)\n",
        "    return U_0_star, U_1_star"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFS_u67iw1e2"
      },
      "source": [
        "## Training and plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU5VfXKsw1e3",
        "lines_to_next_cell": 2
      },
      "source": [
        "\n",
        "# Setup\n",
        "lb = np.array([-1.0])\n",
        "ub = np.array([1.0])\n",
        "idx_t_0 = 10\n",
        "skip = 80\n",
        "idx_t_1 = idx_t_0 + skip\n",
        "\n",
        "# Getting the data\n",
        "path = os.path.join(appDataPath, \"burgers_shock.mat\")\n",
        "x_0, u_0, x_1, u_1, x_star, t_star, dt, q, \\\n",
        "  Exact_u, IRK_alpha, IRK_beta = prep_data(path, N_0=N_0, N_1=N_1,\n",
        "  lb=lb, ub=ub, noise=0.0, idx_t_0=idx_t_0, idx_t_1=idx_t_1)\n",
        "lambdas_star = (1.0, 0.01/np.pi)\n",
        "\n",
        "# Setting the output layer dynamically\n",
        "layers[-1] = q\n",
        " \n",
        "# Creating the model and training\n",
        "logger = Logger(frequency=10)\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, dt, lb, ub, q, IRK_alpha, IRK_beta)\n",
        "def error():\n",
        "  l1, l2 = pinn.get_params(numpy=True)\n",
        "  l1_star, l2_star = lambdas_star\n",
        "  error_lambda_1 = np.abs(l1 - l1_star) / l1_star\n",
        "  error_lambda_2 = np.abs(l2 - l2_star) / l2_star\n",
        "  return (error_lambda_1 + error_lambda_2) / 2\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(x_0, u_0, x_1, u_1, tf_epochs)\n",
        "\n",
        "# Getting the model predictions\n",
        "U_0_pred, U_1_pred = pinn.predict(x_star)\n",
        "lambda_1_pred, lambda_2_pred = pinn.get_params(numpy=True)\n",
        "\n",
        "# Noisy case (same as before with a different noise)\n",
        "x_0, u_0, x_1, u_1, x_star, t_star, dt, q, \\\n",
        "  Exact_u, IRK_alpha, IRK_beta = prep_data(path, N_0=N_0, N_1=N_1,\n",
        "  lb=lb, ub=ub, noise=0.01, idx_t_0=idx_t_0, idx_t_1=idx_t_1)\n",
        "layers[-1] = q\n",
        "pinn = PhysicsInformedNN(layers, tf_optimizer, logger, dt, lb, ub, q, IRK_alpha, IRK_beta)\n",
        "pinn.fit(x_0, u_0, x_1, u_1, tf_epochs)\n",
        "U_0_pred, U_1_pred = pinn.predict(x_star)\n",
        "lambda_1_pred_noisy, lambda_2_pred_noisy = pinn.get_params(numpy=True)\n",
        "\n",
        "print(\"l1: \", lambda_1_pred)\n",
        "print(\"l2: \", lambda_2_pred)\n",
        "print(\"noisy l1: \", lambda_1_pred_noisy)\n",
        "print(\"noisy l2: \", lambda_2_pred_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUtmuGlpw1e6"
      },
      "source": [
        "#plot_ide_disc_results(x_star, t_star, idx_t_0, idx_t_1, x_0, u_0, x_1, u_1,\n",
        "#  ub, lb, U_1_pred, Exact_u, lambda_1_pred, lambda_1_pred_noisy, lambda_2_pred, lambda_2_pred_noisy, x_star, t_star)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}