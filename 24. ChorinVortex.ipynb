{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ChorinVortex.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Source : https://github.com/duypham01/DNNSolPDEs"],"metadata":{"id":"WjjSTy5YdmtP"}},{"cell_type":"code","metadata":{"id":"SbEgqCfKoNUm","executionInfo":{"status":"ok","timestamp":1658284313146,"user_tz":-540,"elapsed":6790,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"source":["# SETUP\n","import random\n","import numpy as np\n","import csv\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import itertools\n","import math\n","import time\n","import tensorflow_probability as tfp\n","import functools\n","\n","pi = math.pi"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipQcEGgiaDap","executionInfo":{"status":"ok","timestamp":1658284314070,"user_tz":-540,"elapsed":928,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"source":["# GENERATING DATA (AND WRITE TO .CSV)\n","def flatArr(x):\n","    y = []\n","    for row in x:\n","        for el in row:\n","            y.append(el)\n","    return np.array(y).flatten()\n","\n","def sampling(x_range, y_range, t_range, t_size, int_size, bound_size):\n","    int_x = np.random.uniform(x_range[0], x_range[1], int_size)\n","    int_y = np.random.uniform(y_range[0], y_range[1], int_size)\n","    Boundary_points = []\n","    for i in range(bound_size):\n","        random_point = [random.uniform(x_range[0], x_range[1]), random.uniform(y_range[0], y_range[1])]\n","        random_index = random.randint(0,1)\n","        if random_index == 0:\n","            random_value = random.choice([x_range[0], x_range[1]])\n","        else:\n","            random_value = random.choice([y_range[0], y_range[1]])\n","        random_point[random_index] = random_value\n","        Boundary_points.append(random_point)\n","    bound_x = np.array(Boundary_points)[:, 0]\n","    bound_y = np.array(Boundary_points)[:, 1]\n","    delta_t = t_range[1]/t_size\n","    int_x_t = np.array([])\n","    int_y_t = np.array([])\n","    bound_x_t = np.array([])\n","    bound_y_t = np.array([])\n","    t = []\n","    tb = []\n","    for i in range(t_size):\n","        t.append([round(t_range[0]+(i+1)*delta_t,6) for e in range(int_x.size)])\n","        int_x_t = np.concatenate((int_x_t, int_x))\n","        int_y_t = np.concatenate((int_y_t, int_y))\n","        tb.append([round(t_range[0]+(i+1)*delta_t,6) for e in range(bound_x.size)])\n","        bound_x_t = np.concatenate((bound_x_t, bound_x))\n","        bound_y_t = np.concatenate((bound_y_t, bound_y))\n","    t = flatArr(t)\n","    tb = flatArr(tb)\n","    # initial points----------------------------------------------\n","    int_x = np.random.uniform(x_range[0], x_range[1], int(int_x_t.size/2))\n","    int_y = np.random.uniform(y_range[0], y_range[1], int(int_x_t.size/2))\n","    Boundary_points = []\n","    for i in range(int(int_x_t.size/2)):\n","        random_point = [random.uniform(x_range[0], x_range[1]), random.uniform(y_range[0], y_range[1])]\n","        random_index = random.randint(0,1)\n","        if random_index == 0:\n","            random_value = random.choice([x_range[0], x_range[1]])\n","        else:\n","            random_value = random.choice([y_range[0], y_range[1]])\n","        random_point[random_index] = random_value\n","        Boundary_points.append(random_point)\n","    bound_x = np.array(Boundary_points)[:, 0]\n","    bound_y = np.array(Boundary_points)[:, 1]\n","    int_x = np.concatenate((int_x, bound_x))\n","    int_y = np.concatenate((int_y, bound_y))\n","    return int_x, int_y, t, int_x_t, int_y_t, tb, bound_x_t, bound_y_t\n","\n","# training data\n","N_train = 1000;        # number of points\n","int_x, int_y, t, int_x_t, int_y_t, tb, bound_x_t, bound_y_t = sampling([0.0, 1.0], [0.0, 1.0], [0.0, 1.0], 10, N_train, N_train)\n","\n","# write training data to .csv file\n","# with open('/content/drive/MyDrive/Papers/Code (chung)/data_train.csv', mode='w') as f:\n","with open('data_train.csv', mode='w') as f:\n","    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    for i in range(t.size):\n","        csv_writer.writerow([int_x_t[i], int_y_t[i], t[i], bound_x_t[i], bound_y_t[i], tb[i], int_x[i], int_y[i], 0.0])\n","\n","\n","# test data\n","N_test = 200;        # number of points\n","int_x, int_y, t, int_x_t, int_y_t, tb, bound_x_t, bound_y_t = sampling([0.0, 1.0], [0.0, 1.0], [0.0, 1.0], 5, N_test, N_test)\n","\n","# write test data to .csv file\n","# with open('/content/drive/MyDrive/Papers/Code (chung)/data_test.csv', mode='w') as f:\n","with open('data_test.csv', mode='w') as f:\n","    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    for i in range(t.size):\n","        csv_writer.writerow([int_x[i], int_y[i], 0.0])\n","    for i in range(t.size):\n","        csv_writer.writerow([int_x_t[i], int_y_t[i], t[i]])\n","    for i in range(t.size):\n","        csv_writer.writerow([bound_x_t[i], bound_y_t[i], tb[i]])"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-sE7XErpOrr","executionInfo":{"status":"ok","timestamp":1658284314456,"user_tz":-540,"elapsed":387,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"source":["# READ DATA\n","\n","# load the dataset\n","# data_train = np.float32(np.loadtxt('/content/drive/MyDrive/Papers/Code (chung)/data_train.csv', delimiter=','))\n","# data_test = np.float32(np.loadtxt('/content/drive/MyDrive/Papers/Code (chung)/data_test.csv', delimiter=','))\n","\n","data_train = np.float32(np.loadtxt('data_train.csv', delimiter=','))\n","data_test = np.float32(np.loadtxt('data_test.csv', delimiter=','))\n","# data_train_test = np.float32(np.loadtxt('data_train_test.csv', delimiter=','))\n","# # split into datasets\n","# P_in = dataset[:,0:2]\n","# P_b = dataset[:,2:4]\n","\n","# # Load NumPy arrays with tf.data.Dataset\n","# P_in = tf.data.Dataset.from_tensor_slices(P_in)\n","# P_b = tf.data.Dataset.from_tensor_slices(P_b)\n","\n","# # Shuffle and batch the datasets\n","# BATCH_SIZE=32\n","# SHUFFLE_BUFFER_SIZE=100\n","\n","# P_in = P_in.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","# P_b = P_b.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6WjxaAVzbqnx","outputId":"3703a0a1-b453-41e6-ec0a-d91bfbb215e7","executionInfo":{"status":"ok","timestamp":1658284314960,"user_tz":-540,"elapsed":507,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"source":["# BUILD NETWORK\n","\n","# dimension of input and output\n","in_dim = 3\n","out_dim = 3\n","\n","# number of neurons on each layer\n","nn = [32, 32, 32, 32, 32]\n","\n","# input layer\n","inputs = keras.Input(shape=(in_dim,), name='points')\n","\n","# hidden layers\n","hidden = keras.layers.Dense(nn[0], activation='tanh', name='hidden_1')(inputs)\n","for i in range(len(nn)-1):\n","    hidden = keras.layers.Dense(nn[i+1], activation='tanh', name='hidden_' + str(i+2))(hidden)\n","\n","# output layer\n","outputs = keras.layers.Dense(out_dim, activation='linear', name=\"u\")(hidden)\n","\n","# create network\n","PDEmodel = keras.Model(inputs=inputs, outputs=outputs, name='chorinvorte')\n","\n","# show network details\n","PDEmodel.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"chorinvorte\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," points (InputLayer)         [(None, 3)]               0         \n","                                                                 \n"," hidden_1 (Dense)            (None, 32)                128       \n","                                                                 \n"," hidden_2 (Dense)            (None, 32)                1056      \n","                                                                 \n"," hidden_3 (Dense)            (None, 32)                1056      \n","                                                                 \n"," hidden_4 (Dense)            (None, 32)                1056      \n","                                                                 \n"," hidden_5 (Dense)            (None, 32)                1056      \n","                                                                 \n"," u (Dense)                   (None, 3)                 99        \n","                                                                 \n","=================================================================\n","Total params: 4,451\n","Trainable params: 4,451\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"x3V4S9yGbsMT","executionInfo":{"status":"ok","timestamp":1658284316214,"user_tz":-540,"elapsed":1258,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"source":["# TRAINING\n","\n","# GRAD U\n","def grad_u(X):\n","    with tf.GradientTape(persistent=True) as tape:\n","        tape.watch(X)\n","        uvp = PDEmodel(X)\n","        u = uvp[:, 0]\n","        v = uvp[:, 1]\n","        p = uvp[:, 2]\n","\n","    u_t = tape.gradient(u, X)[:, 2]\n","    u_x = tape.gradient(u, X)[:, 0]\n","    u_y = tape.gradient(u, X)[:, 1]\n","    v_t = tape.gradient(v, X)[:, 2]\n","    v_x = tape.gradient(v, X)[:, 0]\n","    v_y = tape.gradient(v, X)[:, 1]\n","    p_x = tape.gradient(p, X)[:, 0]\n","    p_y = tape.gradient(p, X)[:, 1]\n","\n","    return u, v, u_t, u_x, u_y, v_t, v_x, v_y, p_x, p_y\n","\n","# return 1D weights\n","def get_weights():\n","    w = []\n","    for layer in PDEmodel.layers[1:]:\n","        weights_biases = layer.get_weights()\n","        weights = weights_biases[0].flatten()\n","        biases = weights_biases[1]\n","        w.extend(weights)\n","        w.extend(biases)\n","    return w\n","\n","# get size of weights in each model's layer\n","sizes_w = []\n","sizes_b = []\n","for layer in PDEmodel.layers[1:]:\n","    weights_biases = layer.get_weights()\n","    sizes_w.append(weights_biases[0].flatten().size)\n","    sizes_b.append(weights_biases[1].size)\n","\n","# convert 1D weights to multi dimension weights in each model's layer\n","def set_weights(w):\n","    for i, layer in enumerate(PDEmodel.layers[1:]):\n","        start_weights = sum(sizes_w[:i]) + sum(sizes_b[:i])\n","        end_weights = sum(sizes_w[:i+1]) + sum(sizes_b[:i])\n","        weights = w[start_weights:end_weights]\n","        w_div = int(sizes_w[i] / sizes_b[i])\n","        weights = tf.reshape(weights, [w_div, sizes_b[i]])\n","        biases = w[end_weights:end_weights + sizes_b[i]]\n","        weights_biases = [weights, biases]\n","        layer.set_weights(weights_biases)\n","\n","losses_hist = []\n","def train(epochs, BATCH_SIZE=128, SHUFFLE_BUFFER_SIZE=100, optimizer = 'adam'):\n","    Re = 100.0\n","    # split into datasets\n","    P_in = data_train[:,0:3]\n","    # P_in_i = P_in[0:N_train]\n","    # P_in = P_in[N_train:]\n","    P_b = data_train[:,3:6]\n","    # P_b_i = P_b[0:N_train]\n","    # P_b = P_b[N_train:]\n","    # P_i = np.concatenate((P_in_i, P_b_i))\n","    P_i = data_train[:, 6:9]\n","    # P_i_tf = tf.convert_to_tensor(P_i, dtype=tf.float32)\n","    # CHOOSE OPTIMIZER\n","    if (optimizer == 'adam'):\n","        optimizer = tf.keras.optimizers.Adam(beta_1=0.9, beta_2=0.999)\n","        # Load NumPy arrays with tf.data.Dataset\n","        P_in = tf.data.Dataset.from_tensor_slices(P_in)\n","        P_b = tf.data.Dataset.from_tensor_slices(P_b)\n","        P_i = tf.data.Dataset.from_tensor_slices(P_i)\n","        # Shuffle and batch the datasets\n","        P_in = P_in.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","        P_b = P_b.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","        P_i = P_i.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","        # for loop epochs\n","        for epoch in range(epochs):\n","            start_epoch = time.time()\n","            # for loop iteration (all batches)\n","            loss = [0]\n","            for (P_in_batch, P_b_batch, P_i_batch) in itertools.zip_longest(P_in, P_b, P_i):\n","                # interior loss\n","                with tf.GradientTape() as tape:\n","                    with tf.GradientTape(persistent=True) as tape1:\n","                        tape1.watch(P_in_batch)\n","                        u, v, u_t, u_x, u_y, v_t, v_x, v_y, p_x, p_y = grad_u(P_in_batch)\n","\n","                    # u_xx and u_yy\n","                    u_xx = tape1.gradient(u_x, P_in_batch)[:,0]\n","                    u_yy = tape1.gradient(u_y, P_in_batch)[:,1]\n","                    v_xx = tape1.gradient(v_x, P_in_batch)[:,0]\n","                    v_yy = tape1.gradient(v_y, P_in_batch)[:,1]\n","                    \n","                    # loss_in_batch\n","                    f_u = u_t - 1/Re*(u_xx + u_yy) + u*u_x + v*u_y + p_x\n","                    f_v = v_t - 1/Re*(v_xx + v_yy) + u*v_x + v*v_y + p_y\n","                    div_u = u_x + v_y\n","                    loss_in_batch = tf.reduce_mean(tf.math.square(f_u)) + \\\n","                                    tf.reduce_mean(tf.math.square(f_v)) + \\\n","                                    tf.reduce_mean(tf.math.square(div_u))\n","                    \n","                    # loss_b_batch\n","                    uvp = PDEmodel(P_b_batch)\n","                    u = uvp[:,0]\n","                    v = uvp[:,1]\n","                    loss_b_batch = tf.reduce_mean(tf.math.square(u + tf.math.cos(pi*P_b_batch[:,0])*tf.math.sin(pi*P_b_batch[:,1])*tf.math.exp(-2.0*pi*pi*P_b_batch[:,2]/Re))) + \\\n","                                   tf.reduce_mean(tf.math.square(v - tf.math.sin(pi*P_b_batch[:,0])*tf.math.cos(pi*P_b_batch[:,1])*tf.math.exp(-2.0*pi*pi*P_b_batch[:,2]/Re)))\n","                    \n","                    # loss_i_batch\n","                    # if (P_i_batch == None):\n","                    #     P_i_batch = P_i_batch_None\n","                    #     P_i_batch = P_i_tf\n","                    uvp = PDEmodel(P_i_batch)\n","                    u = uvp[:,0]\n","                    v = uvp[:,1]\n","                    loss_i_batch = tf.reduce_mean(tf.math.square(u+tf.math.cos(pi*P_i_batch[:,0])*tf.math.sin(pi*P_i_batch[:,1]))) + \\\n","                                   tf.reduce_mean(tf.math.square(v-tf.math.sin(pi*P_i_batch[:,0])*tf.math.cos(pi*P_i_batch[:,1])))\n","                    # P_i_batch_None = P_i_batch\n","\n","                    # total loss\n","                    loss_batch = loss_in_batch + loss_b_batch + loss_i_batch\n","                \n","                # update paremeters\n","                grads = tape.gradient(loss_batch, PDEmodel.weights)\n","                optimizer.apply_gradients(zip(grads, PDEmodel.weights))\n","                \n","                # add loss_batch to loss\n","                loss += loss_batch\n","            \n","            loss = loss/len(list(P_in))\n","            print(\"[%4s] loss = %12.5f \\t %4.3fs\" % (epoch, loss, time.time() - start_epoch))\n","            losses_hist.append(loss.numpy()[0])\n","\n","            # break condition\n","            # if (epoch > 200):\n","            #     if (losses_hist[epoch][0]/losses_hist[epoch-100][0] > 0.9):\n","            #         break\n","\n","    if (optimizer == 'l-bfgs'):\n","        P_in = tf.convert_to_tensor(P_in, dtype=tf.float32)\n","        P_b = tf.convert_to_tensor(P_b, dtype=tf.float32)\n","        P_i = tf.convert_to_tensor(P_i, dtype=tf.float32)\n","        def function_factory(P_in, P_b, P_i):\n","\n","            def loss_grad(weights):\n","                start_epoch = time.time()\n","                with tf.GradientTape() as tape:\n","                    with tf.GradientTape(persistent=True) as tape1:\n","                        set_weights(weights)\n","                        tape1.watch(P_in)\n","                        u, v, u_t, u_x, u_y, v_t, v_x, v_y, p_x, p_y = grad_u(P_in)\n","\n","                    # u_xx and u_yy\n","                    u_xx = tape1.gradient(u_x, P_in)[:,0]\n","                    u_yy = tape1.gradient(u_y, P_in)[:,1]\n","                    v_xx = tape1.gradient(v_x, P_in)[:,0]\n","                    v_yy = tape1.gradient(v_y, P_in)[:,1]\n","\n","                    # loss_in\n","                    # - pi/2*tf.math.sin(2*pi*P_in[:,1])*tf.math.exp(-4*pi*pi*P_in[:,0]/Re)\n","                    # - pi/2*tf.math.sin(2*pi*P_in[:,2])*tf.math.exp(-4*pi*pi*P_in[:,0]/Re)\n","                    f_u = u_t - (1.0/Re)*(u_xx + u_yy) + u*u_x + v*u_y + p_x \n","                    f_v = v_t - (1.0/Re)*(v_xx + v_yy) + u*v_x + v*v_y + p_y \n","                    div_u = u_x + v_y\n","                    loss_in = tf.reduce_mean(tf.math.square(f_u)) + \\\n","                              tf.reduce_mean(tf.math.square(f_v)) + \\\n","                              tf.reduce_mean(tf.math.square(div_u))\n","\n","                    # loss_b\n","                    uvp = PDEmodel(P_b)\n","                    u = uvp[:,0]\n","                    v = uvp[:,1]\n","                    loss_b = tf.reduce_mean(tf.math.square(u + tf.math.cos(pi*P_b[:,0])*tf.math.sin(pi*P_b[:,1])*tf.math.exp(-2.0*pi*pi*P_b[:,2]/Re))) + \\\n","                             tf.reduce_mean(tf.math.square(v - tf.math.sin(pi*P_b[:,0])*tf.math.cos(pi*P_b[:,1])*tf.math.exp(-2.0*pi*pi*P_b[:,2]/Re)))\n","\n","                    # loss_i\n","                    uvp = PDEmodel(P_i)\n","                    u = uvp[:,0]\n","                    v = uvp[:,1]\n","                    loss_i = tf.reduce_mean(tf.math.square(u+tf.math.cos(pi*P_i[:,0])*tf.math.sin(pi*P_i[:,1]))) + \\\n","                             tf.reduce_mean(tf.math.square(v-tf.math.sin(pi*P_i[:,0])*tf.math.cos(pi*P_i[:,1])))\n","\n","                    # total loss\n","                    loss = loss_in + loss_b + loss_i\n","                    print(\"loss = %12.5f \\t %4.3fs\" % (loss, time.time() - start_epoch))\n","                    losses_hist.append(loss.numpy())\n","                grad = tape.gradient(loss, PDEmodel.weights)\n","                grad_1D = []\n","                for g in grad:\n","                    grad_1D.append(tf.reshape(g, [-1]))\n","                grad_1D = tf.concat(grad_1D, 0)\n","                return loss, grad_1D\n","            return loss_grad\n","        # update paremeters\n","\n","        func = function_factory(P_in, P_b, P_i)\n","\n","        # @tf.function\n","        # def epoch():\n","        #     if opt_result is None:\n","        #         return 0\n","        #     return int(opt_result.num_iterations.numpy())\n","        # add loss_batch to loss\n","        opt_result = tfp.optimizer.lbfgs_minimize(func,\n","            tf.convert_to_tensor(get_weights(), dtype=tf.float32),\n","            max_iterations=epochs)\n","    \n","        print(opt_result)\n","        # set_weights(result)\n","        # print(result)\n","\n","        # start = get_weights()\n","        # @tf.function\n","        # def opt_with_bfgs():\n","        #     return tfp.optimizer.lbfgs_minimize(\n","        #         loss_grad,\n","        #         initial_position=tf.convert_to_tensor(start, dtype=tf.float32),\n","        #         max_iterations=epochs)\n","\n","        # results = run(opt_with_bfgs)\n","        # print('BFGS Results')\n","        # print('Converged:', results.converged)\n","        # print('Location of the minimum:', results.position)\n","        # print('Number of iterations:', results.num_iterations)\n","    \n","\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"E24sUnv2mlOK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658288046841,"user_tz":-540,"elapsed":3730628,"user":{"displayName":"박민혁","userId":"04490186307398600319"}},"outputId":"af252bd2-780f-4441-d4fe-4f3fc485986e"},"source":["train(200, optimizer='adam')\n","train(400, optimizer='l-bfgs')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[   0] loss =      0.56278 \t 20.558s\n","[   1] loss =      0.36324 \t 6.723s\n","[   2] loss =      0.32988 \t 6.542s\n","[   3] loss =      0.30386 \t 20.494s\n","[   4] loss =      0.24701 \t 6.717s\n","[   5] loss =      0.16207 \t 6.605s\n","[   6] loss =      0.11614 \t 20.495s\n","[   7] loss =      0.08542 \t 20.497s\n","[   8] loss =      0.06919 \t 20.495s\n","[   9] loss =      0.05780 \t 20.496s\n","[  10] loss =      0.05112 \t 20.494s\n","[  11] loss =      0.04628 \t 10.274s\n","[  12] loss =      0.04110 \t 10.264s\n","[  13] loss =      0.03816 \t 6.717s\n","[  14] loss =      0.03476 \t 40.975s\n","[  15] loss =      0.03128 \t 10.261s\n","[  16] loss =      0.02906 \t 20.497s\n","[  17] loss =      0.02763 \t 6.724s\n","[  18] loss =      0.02501 \t 20.500s\n","[  19] loss =      0.02247 \t 20.496s\n","[  20] loss =      0.02109 \t 20.495s\n","[  21] loss =      0.02002 \t 10.265s\n","[  22] loss =      0.01764 \t 20.498s\n","[  23] loss =      0.01656 \t 20.493s\n","[  24] loss =      0.01531 \t 10.265s\n","[  25] loss =      0.01453 \t 20.496s\n","[  26] loss =      0.01351 \t 40.989s\n","[  27] loss =      0.01267 \t 20.497s\n","[  28] loss =      0.01196 \t 20.495s\n","[  29] loss =      0.01194 \t 10.262s\n","[  30] loss =      0.01040 \t 10.258s\n","[  31] loss =      0.00928 \t 20.538s\n","[  32] loss =      0.00967 \t 6.699s\n","[  33] loss =      0.00863 \t 6.448s\n","[  34] loss =      0.00898 \t 20.496s\n","[  35] loss =      0.00794 \t 10.310s\n","[  36] loss =      0.00744 \t 10.263s\n","[  37] loss =      0.00799 \t 6.577s\n","[  38] loss =      0.00674 \t 6.712s\n","[  39] loss =      0.00600 \t 6.758s\n","[  40] loss =      0.00668 \t 6.498s\n","[  41] loss =      0.00614 \t 6.673s\n","[  42] loss =      0.00615 \t 20.504s\n","[  43] loss =      0.00534 \t 10.262s\n","[  44] loss =      0.00508 \t 6.622s\n","[  45] loss =      0.00487 \t 20.496s\n","[  46] loss =      0.00466 \t 10.264s\n","[  47] loss =      0.00452 \t 10.258s\n","[  48] loss =      0.00471 \t 6.616s\n","[  49] loss =      0.00424 \t 6.494s\n","[  50] loss =      0.00393 \t 20.496s\n","[  51] loss =      0.00404 \t 10.266s\n","[  52] loss =      0.00423 \t 20.503s\n","[  53] loss =      0.00372 \t 20.496s\n","[  54] loss =      0.00331 \t 10.255s\n","[  55] loss =      0.00345 \t 10.254s\n","[  56] loss =      0.00329 \t 6.565s\n","[  57] loss =      0.00342 \t 20.494s\n","[  58] loss =      0.00316 \t 6.639s\n","[  59] loss =      0.00345 \t 20.494s\n","[  60] loss =      0.00302 \t 40.984s\n","[  61] loss =      0.00312 \t 20.502s\n","[  62] loss =      0.00298 \t 10.261s\n","[  63] loss =      0.00264 \t 10.297s\n","[  64] loss =      0.00288 \t 10.261s\n","[  65] loss =      0.00274 \t 20.499s\n","[  66] loss =      0.00261 \t 6.513s\n","[  67] loss =      0.00262 \t 20.495s\n","[  68] loss =      0.00260 \t 10.262s\n","[  69] loss =      0.00257 \t 20.495s\n","[  70] loss =      0.00242 \t 20.499s\n","[  71] loss =      0.00213 \t 20.494s\n","[  72] loss =      0.00212 \t 20.511s\n","[  73] loss =      0.00237 \t 20.498s\n","[  74] loss =      0.00208 \t 6.465s\n","[  75] loss =      0.00198 \t 20.540s\n","[  76] loss =      0.00235 \t 10.261s\n","[  77] loss =      0.00194 \t 20.498s\n","[  78] loss =      0.00183 \t 10.259s\n","[  79] loss =      0.00182 \t 6.344s\n","[  80] loss =      0.00211 \t 10.254s\n","[  81] loss =      0.00209 \t 10.261s\n","[  82] loss =      0.00174 \t 10.261s\n","[  83] loss =      0.00177 \t 6.484s\n","[  84] loss =      0.00164 \t 6.494s\n","[  85] loss =      0.00179 \t 20.495s\n","[  86] loss =      0.00172 \t 20.494s\n","[  87] loss =      0.00166 \t 10.255s\n","[  88] loss =      0.00169 \t 20.499s\n","[  89] loss =      0.00180 \t 10.254s\n","[  90] loss =      0.00148 \t 20.495s\n","[  91] loss =      0.00158 \t 6.369s\n","[  92] loss =      0.00183 \t 20.495s\n","[  93] loss =      0.00174 \t 20.497s\n","[  94] loss =      0.00155 \t 20.508s\n","[  95] loss =      0.00224 \t 10.261s\n","[  96] loss =      0.00122 \t 6.387s\n","[  97] loss =      0.00129 \t 6.403s\n","[  98] loss =      0.00171 \t 20.494s\n","[  99] loss =      0.00198 \t 40.975s\n","[ 100] loss =      0.00144 \t 10.254s\n","[ 101] loss =      0.00130 \t 10.310s\n","[ 102] loss =      0.00131 \t 20.500s\n","[ 103] loss =      0.00111 \t 20.498s\n","[ 104] loss =      0.00116 \t 10.256s\n","[ 105] loss =      0.00111 \t 20.495s\n","[ 106] loss =      0.00116 \t 6.418s\n","[ 107] loss =      0.00133 \t 20.504s\n","[ 108] loss =      0.00121 \t 6.454s\n","[ 109] loss =      0.00123 \t 7.157s\n","[ 110] loss =      0.00099 \t 20.493s\n","[ 111] loss =      0.00099 \t 6.360s\n","[ 112] loss =      0.00126 \t 20.493s\n","[ 113] loss =      0.00119 \t 6.393s\n","[ 114] loss =      0.00165 \t 20.497s\n","[ 115] loss =      0.00110 \t 6.335s\n","[ 116] loss =      0.00096 \t 20.495s\n","[ 117] loss =      0.00126 \t 10.260s\n","[ 118] loss =      0.00087 \t 20.496s\n","[ 119] loss =      0.00118 \t 6.526s\n","[ 120] loss =      0.00109 \t 20.494s\n","[ 121] loss =      0.00112 \t 10.262s\n","[ 122] loss =      0.00085 \t 10.268s\n","[ 123] loss =      0.00081 \t 10.262s\n","[ 124] loss =      0.00106 \t 20.496s\n","[ 125] loss =      0.00116 \t 10.259s\n","[ 126] loss =      0.00103 \t 40.974s\n","[ 127] loss =      0.00064 \t 10.265s\n","[ 128] loss =      0.00063 \t 6.341s\n","[ 129] loss =      0.00078 \t 6.406s\n","[ 130] loss =      0.00064 \t 20.539s\n","[ 131] loss =      0.00129 \t 6.463s\n","[ 132] loss =      0.00118 \t 20.540s\n","[ 133] loss =      0.00089 \t 10.261s\n","[ 134] loss =      0.00077 \t 10.266s\n","[ 135] loss =      0.00062 \t 20.496s\n","[ 136] loss =      0.00065 \t 20.494s\n","[ 137] loss =      0.00082 \t 6.355s\n","[ 138] loss =      0.00073 \t 20.494s\n","[ 139] loss =      0.00069 \t 6.474s\n","[ 140] loss =      0.00085 \t 6.453s\n","[ 141] loss =      0.00053 \t 7.208s\n","[ 142] loss =      0.00093 \t 6.404s\n","[ 143] loss =      0.00074 \t 10.253s\n","[ 144] loss =      0.00073 \t 6.424s\n","[ 145] loss =      0.00090 \t 20.503s\n","[ 146] loss =      0.00061 \t 6.428s\n","[ 147] loss =      0.00051 \t 6.496s\n","[ 148] loss =      0.00074 \t 20.496s\n","[ 149] loss =      0.00056 \t 10.258s\n","[ 150] loss =      0.00071 \t 6.379s\n","[ 151] loss =      0.00051 \t 6.490s\n","[ 152] loss =      0.00086 \t 20.496s\n","[ 153] loss =      0.00091 \t 20.498s\n","[ 154] loss =      0.00110 \t 6.439s\n","[ 155] loss =      0.00049 \t 40.977s\n","[ 156] loss =      0.00065 \t 10.262s\n","[ 157] loss =      0.00042 \t 20.495s\n","[ 158] loss =      0.00051 \t 10.261s\n","[ 159] loss =      0.00069 \t 10.266s\n","[ 160] loss =      0.00050 \t 10.270s\n","[ 161] loss =      0.00091 \t 10.256s\n","[ 162] loss =      0.00057 \t 20.503s\n","[ 163] loss =      0.00120 \t 10.260s\n","[ 164] loss =      0.00061 \t 10.256s\n","[ 165] loss =      0.00041 \t 10.261s\n","[ 166] loss =      0.00082 \t 10.264s\n","[ 167] loss =      0.00066 \t 10.262s\n","[ 168] loss =      0.00042 \t 20.495s\n","[ 169] loss =      0.00047 \t 20.494s\n","[ 170] loss =      0.00054 \t 20.493s\n","[ 171] loss =      0.00045 \t 10.274s\n","[ 172] loss =      0.00084 \t 10.263s\n","[ 173] loss =      0.00050 \t 10.258s\n","[ 174] loss =      0.00044 \t 20.496s\n","[ 175] loss =      0.00049 \t 20.494s\n","[ 176] loss =      0.00071 \t 20.540s\n","[ 177] loss =      0.00092 \t 6.635s\n","[ 178] loss =      0.00077 \t 6.485s\n","[ 179] loss =      0.00050 \t 6.473s\n","[ 180] loss =      0.00091 \t 6.449s\n","[ 181] loss =      0.00156 \t 20.498s\n","[ 182] loss =      0.00042 \t 6.460s\n","[ 183] loss =      0.00056 \t 20.497s\n","[ 184] loss =      0.00038 \t 20.493s\n","[ 185] loss =      0.00052 \t 10.261s\n","[ 186] loss =      0.00034 \t 20.495s\n","[ 187] loss =      0.00032 \t 6.490s\n","[ 188] loss =      0.00046 \t 6.576s\n","[ 189] loss =      0.00046 \t 20.493s\n","[ 190] loss =      0.00038 \t 10.305s\n","[ 191] loss =      0.00057 \t 20.509s\n","[ 192] loss =      0.00079 \t 6.451s\n","[ 193] loss =      0.00056 \t 20.505s\n","[ 194] loss =      0.00032 \t 10.263s\n","[ 195] loss =      0.00072 \t 20.495s\n","[ 196] loss =      0.00053 \t 20.495s\n","[ 197] loss =      0.00037 \t 20.494s\n","[ 198] loss =      0.00064 \t 6.460s\n","[ 199] loss =      0.00071 \t 20.508s\n","loss =      0.00079 \t 0.412s\n","loss =     13.82883 \t 0.281s\n","loss =      0.00069 \t 0.283s\n","loss =      0.00063 \t 0.279s\n","loss =      0.00041 \t 0.291s\n","loss =      0.00280 \t 0.280s\n","loss =      0.00041 \t 0.310s\n","loss =      0.00037 \t 0.329s\n","loss =      0.00043 \t 0.319s\n","loss =      0.00036 \t 0.314s\n","loss =      0.00034 \t 0.330s\n","loss =      0.00036 \t 0.307s\n","loss =      0.00033 \t 0.316s\n","loss =      0.00032 \t 0.309s\n","loss =      0.00046 \t 0.329s\n","loss =      0.00032 \t 0.306s\n","loss =      0.00031 \t 0.318s\n","loss =      0.00031 \t 0.309s\n","loss =      0.00030 \t 0.322s\n","loss =      0.00029 \t 0.307s\n","loss =      0.00035 \t 0.309s\n","loss =      0.00029 \t 0.321s\n","loss =      0.00029 \t 0.326s\n","loss =      0.00030 \t 0.308s\n","loss =      0.00028 \t 0.314s\n","loss =      0.00028 \t 0.324s\n","loss =      0.00027 \t 0.313s\n","loss =      0.00043 \t 0.308s\n","loss =      0.00027 \t 0.306s\n","loss =      0.00026 \t 0.323s\n","loss =      0.00027 \t 0.314s\n","loss =      0.00026 \t 0.309s\n","loss =      0.00025 \t 0.327s\n","loss =      0.00030 \t 0.299s\n","loss =      0.00025 \t 0.286s\n","loss =      0.00024 \t 0.313s\n","loss =      0.00024 \t 0.327s\n","loss =      0.00023 \t 0.312s\n","loss =      0.00023 \t 0.323s\n","loss =      0.00029 \t 0.311s\n","loss =      0.00023 \t 0.322s\n","loss =      0.00022 \t 0.318s\n","loss =      0.00022 \t 0.317s\n","loss =      0.00022 \t 0.331s\n","loss =      0.00023 \t 0.308s\n","loss =      0.00022 \t 0.314s\n","loss =      0.00022 \t 0.310s\n","loss =      0.00022 \t 0.322s\n","loss =      0.00022 \t 0.310s\n","loss =      0.00021 \t 0.314s\n","loss =      0.00024 \t 0.322s\n","loss =      0.00021 \t 0.326s\n","loss =      0.00021 \t 0.307s\n","loss =      0.00021 \t 0.310s\n","loss =      0.00021 \t 0.325s\n","loss =      0.00021 \t 0.315s\n","loss =      0.00021 \t 0.305s\n","loss =      0.00021 \t 0.277s\n","loss =      0.00021 \t 0.330s\n","loss =      0.00021 \t 0.310s\n","loss =      0.00021 \t 0.306s\n","loss =      0.00020 \t 0.321s\n","loss =      0.00020 \t 0.311s\n","loss =      0.00020 \t 0.288s\n","loss =      0.00020 \t 0.322s\n","loss =      0.00020 \t 0.320s\n","loss =      0.00020 \t 0.323s\n","loss =      0.00020 \t 0.317s\n","loss =      0.00020 \t 0.327s\n","loss =      0.00019 \t 0.308s\n","loss =      0.00019 \t 0.316s\n","loss =      0.00020 \t 0.311s\n","loss =      0.00019 \t 0.326s\n","loss =      0.00019 \t 0.318s\n","loss =      0.00019 \t 0.305s\n","loss =      0.00019 \t 0.312s\n","loss =      0.00019 \t 0.325s\n","loss =      0.00019 \t 0.308s\n","loss =      0.00019 \t 0.314s\n","loss =      0.00020 \t 0.315s\n","loss =      0.00019 \t 0.319s\n","loss =      0.00018 \t 0.312s\n","loss =      0.00021 \t 0.316s\n","loss =      0.00018 \t 0.321s\n","loss =      0.00018 \t 0.316s\n","loss =      0.00019 \t 0.305s\n","loss =      0.00018 \t 0.309s\n","loss =      0.00018 \t 0.325s\n","loss =      0.00018 \t 0.306s\n","loss =      0.00018 \t 0.308s\n","loss =      0.00018 \t 0.320s\n","loss =      0.00019 \t 0.309s\n","loss =      0.00018 \t 0.311s\n","loss =      0.00018 \t 0.306s\n","loss =      0.00018 \t 0.317s\n","loss =      0.00018 \t 0.338s\n","loss =      0.00018 \t 0.483s\n","loss =      0.00018 \t 0.463s\n","loss =      0.00018 \t 0.319s\n","loss =      0.00018 \t 0.321s\n","loss =      0.00018 \t 0.316s\n","loss =      0.00018 \t 0.304s\n","loss =      0.00018 \t 0.282s\n","loss =      0.00018 \t 0.296s\n","loss =      0.00018 \t 0.313s\n","loss =      0.00017 \t 0.322s\n","loss =      0.00019 \t 0.330s\n","loss =      0.00017 \t 0.306s\n","loss =      0.00017 \t 0.289s\n","loss =      0.00017 \t 0.317s\n","loss =      0.00017 \t 0.316s\n","loss =      0.00017 \t 0.329s\n","loss =      0.00017 \t 0.310s\n","loss =      0.00017 \t 0.320s\n","loss =      0.00017 \t 0.297s\n","loss =      0.00018 \t 0.284s\n","loss =      0.00017 \t 0.282s\n","loss =      0.00017 \t 0.289s\n","loss =      0.00017 \t 0.279s\n","loss =      0.00017 \t 0.291s\n","loss =      0.00017 \t 0.291s\n","loss =      0.00017 \t 0.295s\n","loss =      0.00017 \t 0.293s\n","loss =      0.00017 \t 0.305s\n","loss =      0.00018 \t 0.293s\n","loss =      0.00017 \t 0.321s\n","loss =      0.00017 \t 0.293s\n","loss =      0.00017 \t 0.294s\n","loss =      0.00017 \t 0.311s\n","loss =      0.00017 \t 0.310s\n","loss =      0.00018 \t 0.322s\n","loss =      0.00017 \t 0.308s\n","loss =      0.00017 \t 0.313s\n","loss =      0.00017 \t 0.309s\n","loss =      0.00017 \t 0.324s\n","loss =      0.00017 \t 0.305s\n","loss =      0.00017 \t 0.305s\n","loss =      0.00017 \t 0.308s\n","loss =      0.00017 \t 0.287s\n","loss =      0.00017 \t 0.324s\n","loss =      0.00017 \t 0.310s\n","loss =      0.00017 \t 0.336s\n","loss =      0.00017 \t 0.308s\n","loss =      0.00017 \t 0.287s\n","loss =      0.00017 \t 0.301s\n","loss =      0.00017 \t 0.282s\n","loss =      0.00017 \t 0.312s\n","loss =      0.00017 \t 0.318s\n","loss =      0.00017 \t 0.320s\n","loss =      0.00017 \t 0.314s\n","loss =      0.00017 \t 0.303s\n","loss =      0.00017 \t 0.328s\n","loss =      0.00017 \t 0.320s\n","loss =      0.00017 \t 0.321s\n","loss =      0.00017 \t 0.311s\n","loss =      0.00016 \t 0.323s\n","loss =      0.00016 \t 0.321s\n","loss =      0.00017 \t 0.312s\n","loss =      0.00016 \t 0.334s\n","loss =      0.00016 \t 0.332s\n","loss =      0.00016 \t 0.322s\n","loss =      0.00016 \t 0.318s\n","loss =      0.00016 \t 0.328s\n","loss =      0.00016 \t 0.312s\n","loss =      0.00016 \t 0.311s\n","loss =      0.00016 \t 0.327s\n","loss =      0.00016 \t 0.332s\n","loss =      0.00016 \t 0.305s\n","loss =      0.00016 \t 0.319s\n","loss =      0.00016 \t 0.310s\n","loss =      0.00016 \t 0.340s\n","loss =      0.00017 \t 0.313s\n","loss =      0.00016 \t 0.312s\n","loss =      0.00016 \t 0.314s\n","loss =      0.00016 \t 0.317s\n","loss =      0.00016 \t 0.324s\n","loss =      0.00016 \t 0.315s\n","loss =      0.00016 \t 0.309s\n","loss =      0.00016 \t 0.314s\n","loss =      0.00016 \t 0.308s\n","loss =      0.00016 \t 0.313s\n","loss =      0.00016 \t 0.308s\n","loss =      0.00016 \t 0.314s\n","loss =      0.00016 \t 0.306s\n","loss =      0.00016 \t 0.339s\n","loss =      0.00016 \t 0.308s\n","loss =      0.00016 \t 0.286s\n","loss =      0.00016 \t 0.283s\n","loss =      0.00016 \t 0.306s\n","loss =      0.00017 \t 0.309s\n","loss =      0.00016 \t 0.284s\n","loss =      0.00016 \t 0.321s\n","loss =      0.00016 \t 0.314s\n","loss =      0.00016 \t 0.321s\n","loss =      0.00016 \t 0.325s\n","loss =      0.00016 \t 0.310s\n","loss =      0.00016 \t 0.283s\n","loss =      0.00016 \t 0.286s\n","loss =      0.00016 \t 0.292s\n","loss =      0.00016 \t 0.288s\n","loss =      0.00016 \t 0.281s\n","loss =      0.00016 \t 0.294s\n","loss =      0.00016 \t 0.319s\n","loss =      0.00016 \t 0.313s\n","loss =      0.00016 \t 0.333s\n","loss =      0.00016 \t 0.322s\n","loss =      0.00016 \t 0.319s\n","loss =      0.00016 \t 0.314s\n","loss =      0.00015 \t 0.325s\n","loss =      0.00015 \t 0.309s\n","loss =      0.00016 \t 0.312s\n","loss =      0.00015 \t 0.338s\n","loss =      0.00015 \t 0.327s\n","loss =      0.00015 \t 0.313s\n","loss =      0.00015 \t 0.316s\n","loss =      0.00015 \t 0.318s\n","loss =      0.00015 \t 0.314s\n","loss =      0.00015 \t 0.281s\n","loss =      0.00015 \t 0.287s\n","loss =      0.00015 \t 0.286s\n","loss =      0.00015 \t 0.304s\n","loss =      0.00015 \t 0.311s\n","loss =      0.00016 \t 0.315s\n","loss =      0.00015 \t 0.318s\n","loss =      0.00015 \t 0.311s\n","loss =      0.00015 \t 0.323s\n","loss =      0.00015 \t 0.321s\n","loss =      0.00015 \t 0.313s\n","loss =      0.00015 \t 0.314s\n","loss =      0.00015 \t 0.322s\n","loss =      0.00015 \t 0.317s\n","loss =      0.00015 \t 0.319s\n","loss =      0.00015 \t 0.308s\n","loss =      0.00015 \t 0.319s\n","loss =      0.00015 \t 0.306s\n","loss =      0.00015 \t 0.303s\n","loss =      0.00015 \t 0.319s\n","loss =      0.00015 \t 0.319s\n","loss =      0.00015 \t 0.279s\n","loss =      0.00015 \t 0.311s\n","loss =      0.00015 \t 0.325s\n","loss =      0.00015 \t 0.318s\n","loss =      0.00015 \t 0.291s\n","loss =      0.00015 \t 0.295s\n","loss =      0.00015 \t 0.300s\n","loss =      0.00015 \t 0.445s\n","loss =      0.00015 \t 0.463s\n","loss =      0.00015 \t 0.318s\n","loss =      0.00015 \t 0.316s\n","loss =      0.00015 \t 0.309s\n","loss =      0.00015 \t 0.283s\n","loss =      0.00015 \t 0.318s\n","loss =      0.00016 \t 0.332s\n","loss =      0.00015 \t 0.315s\n","loss =      0.00015 \t 0.332s\n","loss =      0.00015 \t 0.330s\n","loss =      0.00015 \t 0.304s\n","loss =      0.00015 \t 0.294s\n","loss =      0.00015 \t 0.328s\n","loss =      0.00015 \t 0.291s\n","loss =      0.00015 \t 0.293s\n","loss =      0.00015 \t 0.293s\n","loss =      0.00014 \t 0.310s\n","loss =      0.00014 \t 0.336s\n","loss =      0.00014 \t 0.316s\n","loss =      0.00014 \t 0.314s\n","loss =      0.00014 \t 0.282s\n","loss =      0.00014 \t 0.287s\n","loss =      0.00014 \t 0.281s\n","loss =      0.00014 \t 0.316s\n","loss =      0.00014 \t 0.311s\n","loss =      0.00014 \t 0.302s\n","loss =      0.00014 \t 0.281s\n","loss =      0.00014 \t 0.293s\n","loss =      0.00014 \t 0.286s\n","loss =      0.00014 \t 0.288s\n","loss =      0.00014 \t 0.319s\n","loss =      0.00014 \t 0.315s\n","loss =      0.00014 \t 0.322s\n","loss =      0.00014 \t 0.311s\n","loss =      0.00014 \t 0.312s\n","loss =      0.00014 \t 0.297s\n","loss =      0.00014 \t 0.276s\n","loss =      0.00014 \t 0.311s\n","loss =      0.00014 \t 0.317s\n","loss =      0.00014 \t 0.283s\n","loss =      0.00014 \t 0.291s\n","loss =      0.00014 \t 0.298s\n","loss =      0.00014 \t 0.307s\n","loss =      0.00014 \t 0.337s\n","loss =      0.00014 \t 0.324s\n","loss =      0.00014 \t 0.295s\n","loss =      0.00014 \t 0.281s\n","loss =      0.00014 \t 0.302s\n","loss =      0.00014 \t 0.285s\n","loss =      0.00014 \t 0.314s\n","loss =      0.00014 \t 0.332s\n","loss =      0.00014 \t 0.314s\n","loss =      0.00014 \t 0.296s\n","loss =      0.00014 \t 0.323s\n","loss =      0.00014 \t 0.324s\n","loss =      0.00014 \t 0.297s\n","loss =      0.00014 \t 0.287s\n","loss =      0.00013 \t 0.295s\n","loss =      0.00014 \t 0.294s\n","loss =      0.00013 \t 0.313s\n","loss =      0.00013 \t 0.325s\n","loss =      0.00013 \t 0.323s\n","loss =      0.00013 \t 0.331s\n","loss =      0.00013 \t 0.311s\n","loss =      0.00013 \t 0.319s\n","loss =      0.00013 \t 0.322s\n","loss =      0.00013 \t 0.286s\n","loss =      0.00014 \t 0.311s\n","loss =      0.00013 \t 0.330s\n","loss =      0.00013 \t 0.316s\n","loss =      0.00013 \t 0.307s\n","loss =      0.00013 \t 0.311s\n","loss =      0.00013 \t 0.328s\n","loss =      0.00013 \t 0.313s\n","loss =      0.00013 \t 0.326s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00013 \t 0.314s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00013 \t 0.320s\n","loss =      0.00013 \t 0.329s\n","loss =      0.00013 \t 0.311s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00014 \t 0.321s\n","loss =      0.00013 \t 0.338s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00013 \t 0.310s\n","loss =      0.00013 \t 0.319s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00013 \t 0.314s\n","loss =      0.00013 \t 0.295s\n","loss =      0.00013 \t 0.285s\n","loss =      0.00013 \t 0.308s\n","loss =      0.00013 \t 0.318s\n","loss =      0.00013 \t 0.320s\n","loss =      0.00013 \t 0.320s\n","loss =      0.00013 \t 0.310s\n","loss =      0.00013 \t 0.324s\n","loss =      0.00013 \t 0.313s\n","loss =      0.00013 \t 0.283s\n","loss =      0.00013 \t 0.280s\n","loss =      0.00013 \t 0.302s\n","loss =      0.00013 \t 0.320s\n","loss =      0.00012 \t 0.305s\n","loss =      0.00013 \t 0.321s\n","loss =      0.00012 \t 0.316s\n","loss =      0.00012 \t 0.289s\n","loss =      0.00013 \t 0.286s\n","loss =      0.00012 \t 0.294s\n","loss =      0.00012 \t 0.311s\n","loss =      0.00012 \t 0.321s\n","loss =      0.00012 \t 0.331s\n","loss =      0.00012 \t 0.300s\n","loss =      0.00012 \t 0.307s\n","loss =      0.00012 \t 0.316s\n","loss =      0.00012 \t 0.323s\n","loss =      0.00012 \t 0.308s\n","loss =      0.00012 \t 0.287s\n","loss =      0.00012 \t 0.287s\n","loss =      0.00012 \t 0.286s\n","loss =      0.00012 \t 0.279s\n","loss =      0.00012 \t 0.309s\n","loss =      0.00012 \t 0.313s\n","loss =      0.00012 \t 0.316s\n","loss =      0.00012 \t 0.323s\n","loss =      0.00012 \t 0.324s\n","loss =      0.00012 \t 0.314s\n","loss =      0.00012 \t 0.313s\n","loss =      0.00012 \t 0.310s\n","loss =      0.00012 \t 0.324s\n","loss =      0.00012 \t 0.300s\n","loss =      0.00012 \t 0.314s\n","loss =      0.00012 \t 0.311s\n","loss =      0.00012 \t 0.289s\n","loss =      0.00012 \t 0.305s\n","loss =      0.00012 \t 0.319s\n","loss =      0.00013 \t 0.320s\n","loss =      0.00012 \t 0.319s\n","loss =      0.00012 \t 0.280s\n","loss =      0.00012 \t 0.321s\n","loss =      0.00012 \t 0.331s\n","loss =      0.00012 \t 0.318s\n","loss =      0.00012 \t 0.310s\n","loss =      0.00012 \t 0.332s\n","loss =      0.00012 \t 0.317s\n","loss =      0.00012 \t 0.313s\n","loss =      0.00012 \t 0.313s\n","loss =      0.00012 \t 0.326s\n","loss =      0.00012 \t 0.488s\n","loss =      0.00012 \t 0.488s\n","loss =      0.00012 \t 0.303s\n","loss =      0.00012 \t 0.304s\n","loss =      0.00012 \t 0.315s\n","loss =      0.00012 \t 0.319s\n","loss =      0.00012 \t 0.289s\n","loss =      0.00012 \t 0.308s\n","loss =      0.00012 \t 0.317s\n","loss =      0.00012 \t 0.316s\n","loss =      0.00012 \t 0.323s\n","loss =      0.00012 \t 0.288s\n","loss =      0.00012 \t 0.308s\n","loss =      0.00012 \t 0.320s\n","loss =      0.00012 \t 0.290s\n","loss =      0.00011 \t 0.309s\n","loss =      0.00011 \t 0.289s\n","loss =      0.00011 \t 0.317s\n","loss =      0.00011 \t 0.290s\n","loss =      0.00012 \t 0.281s\n","loss =      0.00011 \t 0.314s\n","loss =      0.00011 \t 0.308s\n","loss =      0.00011 \t 0.320s\n","loss =      0.00011 \t 0.306s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.305s\n","loss =      0.00011 \t 0.323s\n","loss =      0.00012 \t 0.313s\n","loss =      0.00011 \t 0.319s\n","loss =      0.00011 \t 0.308s\n","loss =      0.00011 \t 0.276s\n","loss =      0.00011 \t 0.278s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00011 \t 0.308s\n","loss =      0.00011 \t 0.285s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.328s\n","loss =      0.00011 \t 0.309s\n","loss =      0.00011 \t 0.310s\n","loss =      0.00011 \t 0.320s\n","loss =      0.00011 \t 0.323s\n","loss =      0.00011 \t 0.319s\n","loss =      0.00011 \t 0.289s\n","loss =      0.00011 \t 0.312s\n","loss =      0.00011 \t 0.313s\n","loss =      0.00011 \t 0.310s\n","loss =      0.00011 \t 0.293s\n","loss =      0.00011 \t 0.285s\n","loss =      0.00011 \t 0.286s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00011 \t 0.325s\n","loss =      0.00011 \t 0.282s\n","loss =      0.00011 \t 0.311s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.305s\n","loss =      0.00011 \t 0.283s\n","loss =      0.00011 \t 0.296s\n","loss =      0.00011 \t 0.295s\n","loss =      0.00011 \t 0.321s\n","loss =      0.00011 \t 0.287s\n","loss =      0.00011 \t 0.290s\n","loss =      0.00011 \t 0.291s\n","loss =      0.00011 \t 0.297s\n","loss =      0.00011 \t 0.294s\n","loss =      0.00011 \t 0.285s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.321s\n","loss =      0.00011 \t 0.314s\n","loss =      0.00011 \t 0.310s\n","loss =      0.00011 \t 0.298s\n","loss =      0.00011 \t 0.290s\n","loss =      0.00011 \t 0.275s\n","loss =      0.00011 \t 0.291s\n","loss =      0.00011 \t 0.285s\n","loss =      0.00011 \t 0.284s\n","loss =      0.00011 \t 0.291s\n","loss =      0.00011 \t 0.281s\n","loss =      0.00011 \t 0.295s\n","loss =      0.00011 \t 0.282s\n","loss =      0.00011 \t 0.284s\n","loss =      0.00011 \t 0.307s\n","loss =      0.00011 \t 0.309s\n","loss =      0.00011 \t 0.325s\n","loss =      0.00011 \t 0.311s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.311s\n","loss =      0.00011 \t 0.329s\n","loss =      0.00011 \t 0.312s\n","loss =      0.00011 \t 0.307s\n","loss =      0.00011 \t 0.311s\n","loss =      0.00011 \t 0.291s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.318s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00011 \t 0.284s\n","loss =      0.00011 \t 0.287s\n","loss =      0.00011 \t 0.292s\n","loss =      0.00011 \t 0.286s\n","loss =      0.00011 \t 0.316s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00011 \t 0.278s\n","loss =      0.00011 \t 0.309s\n","loss =      0.00011 \t 0.320s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00011 \t 0.318s\n","loss =      0.00011 \t 0.317s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00011 \t 0.307s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00011 \t 0.307s\n","loss =      0.00010 \t 0.320s\n","loss =      0.00010 \t 0.307s\n","loss =      0.00010 \t 0.306s\n","loss =      0.00010 \t 0.310s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00011 \t 0.305s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00010 \t 0.320s\n","loss =      0.00011 \t 0.314s\n","loss =      0.00010 \t 0.279s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.313s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.278s\n","loss =      0.00010 \t 0.312s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.328s\n","loss =      0.00010 \t 0.286s\n","loss =      0.00011 \t 0.315s\n","loss =      0.00010 \t 0.330s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.278s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.318s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.304s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.289s\n","loss =      0.00010 \t 0.303s\n","loss =      0.00010 \t 0.331s\n","loss =      0.00010 \t 0.305s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.317s\n","loss =      0.00010 \t 0.319s\n","loss =      0.00010 \t 0.312s\n","loss =      0.00010 \t 0.300s\n","loss =      0.00010 \t 0.285s\n","loss =      0.00010 \t 0.328s\n","loss =      0.00010 \t 0.409s\n","loss =      0.00010 \t 0.477s\n","loss =      0.00010 \t 0.364s\n","loss =      0.00010 \t 0.319s\n","loss =      0.00010 \t 0.320s\n","loss =      0.00010 \t 0.313s\n","loss =      0.00010 \t 0.328s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.307s\n","loss =      0.00010 \t 0.313s\n","loss =      0.00010 \t 0.325s\n","loss =      0.00010 \t 0.305s\n","loss =      0.00010 \t 0.312s\n","loss =      0.00010 \t 0.312s\n","loss =      0.00010 \t 0.324s\n","loss =      0.00010 \t 0.277s\n","loss =      0.00010 \t 0.281s\n","loss =      0.00010 \t 0.303s\n","loss =      0.00010 \t 0.337s\n","loss =      0.00010 \t 0.288s\n","loss =      0.00010 \t 0.284s\n","loss =      0.00010 \t 0.282s\n","loss =      0.00010 \t 0.318s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.324s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.298s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.319s\n","loss =      0.00010 \t 0.310s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00010 \t 0.330s\n","loss =      0.00010 \t 0.307s\n","loss =      0.00010 \t 0.330s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.298s\n","loss =      0.00010 \t 0.299s\n","loss =      0.00010 \t 0.283s\n","loss =      0.00010 \t 0.308s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.322s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00010 \t 0.313s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.290s\n","loss =      0.00010 \t 0.285s\n","loss =      0.00010 \t 0.334s\n","loss =      0.00010 \t 0.326s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00010 \t 0.323s\n","loss =      0.00010 \t 0.332s\n","loss =      0.00010 \t 0.324s\n","loss =      0.00010 \t 0.286s\n","loss =      0.00010 \t 0.317s\n","loss =      0.00010 \t 0.312s\n","loss =      0.00010 \t 0.327s\n","loss =      0.00010 \t 0.282s\n","loss =      0.00010 \t 0.302s\n","loss =      0.00010 \t 0.313s\n","loss =      0.00010 \t 0.306s\n","loss =      0.00010 \t 0.291s\n","loss =      0.00010 \t 0.288s\n","loss =      0.00010 \t 0.319s\n","loss =      0.00010 \t 0.292s\n","loss =      0.00010 \t 0.287s\n","loss =      0.00010 \t 0.291s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00010 \t 0.280s\n","loss =      0.00010 \t 0.283s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.301s\n","loss =      0.00010 \t 0.313s\n","loss =      0.00010 \t 0.320s\n","loss =      0.00010 \t 0.307s\n","loss =      0.00010 \t 0.303s\n","loss =      0.00010 \t 0.323s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00010 \t 0.321s\n","loss =      0.00010 \t 0.308s\n","loss =      0.00010 \t 0.307s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.322s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.308s\n","loss =      0.00010 \t 0.324s\n","loss =      0.00010 \t 0.302s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.326s\n","loss =      0.00010 \t 0.303s\n","loss =      0.00010 \t 0.309s\n","loss =      0.00010 \t 0.319s\n","loss =      0.00010 \t 0.314s\n","loss =      0.00010 \t 0.305s\n","loss =      0.00010 \t 0.311s\n","loss =      0.00010 \t 0.319s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00010 \t 0.283s\n","loss =      0.00010 \t 0.284s\n","loss =      0.00010 \t 0.292s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00010 \t 0.292s\n","loss =      0.00010 \t 0.303s\n","loss =      0.00010 \t 0.278s\n","loss =      0.00010 \t 0.289s\n","loss =      0.00010 \t 0.302s\n","loss =      0.00010 \t 0.279s\n","loss =      0.00010 \t 0.318s\n","loss =      0.00010 \t 0.324s\n","loss =      0.00009 \t 0.323s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00010 \t 0.316s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.281s\n","loss =      0.00010 \t 0.312s\n","loss =      0.00009 \t 0.322s\n","loss =      0.00009 \t 0.280s\n","loss =      0.00009 \t 0.295s\n","loss =      0.00009 \t 0.296s\n","loss =      0.00009 \t 0.288s\n","loss =      0.00009 \t 0.282s\n","loss =      0.00009 \t 0.291s\n","loss =      0.00009 \t 0.281s\n","loss =      0.00009 \t 0.283s\n","loss =      0.00009 \t 0.296s\n","loss =      0.00009 \t 0.280s\n","loss =      0.00009 \t 0.288s\n","loss =      0.00009 \t 0.287s\n","loss =      0.00009 \t 0.305s\n","loss =      0.00010 \t 0.287s\n","loss =      0.00009 \t 0.289s\n","loss =      0.00009 \t 0.282s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.305s\n","loss =      0.00009 \t 0.289s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.325s\n","loss =      0.00009 \t 0.313s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.324s\n","loss =      0.00009 \t 0.323s\n","loss =      0.00009 \t 0.489s\n","loss =      0.00009 \t 0.474s\n","loss =      0.00009 \t 0.309s\n","loss =      0.00010 \t 0.315s\n","loss =      0.00009 \t 0.313s\n","loss =      0.00009 \t 0.313s\n","loss =      0.00009 \t 0.309s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.311s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00009 \t 0.322s\n","loss =      0.00009 \t 0.321s\n","loss =      0.00009 \t 0.323s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.339s\n","loss =      0.00009 \t 0.325s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.320s\n","loss =      0.00009 \t 0.323s\n","loss =      0.00009 \t 0.333s\n","loss =      0.00009 \t 0.281s\n","loss =      0.00009 \t 0.288s\n","loss =      0.00009 \t 0.292s\n","loss =      0.00009 \t 0.283s\n","loss =      0.00009 \t 0.292s\n","loss =      0.00009 \t 0.302s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.322s\n","loss =      0.00009 \t 0.311s\n","loss =      0.00009 \t 0.284s\n","loss =      0.00009 \t 0.319s\n","loss =      0.00009 \t 0.314s\n","loss =      0.00009 \t 0.329s\n","loss =      0.00009 \t 0.320s\n","loss =      0.00009 \t 0.310s\n","loss =      0.00009 \t 0.321s\n","loss =      0.00009 \t 0.325s\n","loss =      0.00009 \t 0.309s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.325s\n","loss =      0.00009 \t 0.320s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.323s\n","loss =      0.00009 \t 0.320s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.312s\n","loss =      0.00009 \t 0.326s\n","loss =      0.00009 \t 0.313s\n","loss =      0.00009 \t 0.308s\n","loss =      0.00009 \t 0.314s\n","loss =      0.00009 \t 0.323s\n","loss =      0.00009 \t 0.320s\n","loss =      0.00009 \t 0.286s\n","loss =      0.00009 \t 0.319s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.314s\n","loss =      0.00009 \t 0.311s\n","loss =      0.00009 \t 0.319s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.318s\n","loss =      0.00009 \t 0.320s\n","loss =      0.00009 \t 0.318s\n","loss =      0.00009 \t 0.322s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.309s\n","loss =      0.00009 \t 0.318s\n","loss =      0.00009 \t 0.311s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.321s\n","loss =      0.00009 \t 0.282s\n","loss =      0.00009 \t 0.285s\n","loss =      0.00009 \t 0.292s\n","loss =      0.00009 \t 0.280s\n","loss =      0.00009 \t 0.274s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.318s\n","loss =      0.00009 \t 0.278s\n","loss =      0.00009 \t 0.287s\n","loss =      0.00009 \t 0.287s\n","loss =      0.00009 \t 0.287s\n","loss =      0.00009 \t 0.283s\n","loss =      0.00009 \t 0.286s\n","loss =      0.00009 \t 0.287s\n","loss =      0.00009 \t 0.311s\n","loss =      0.00009 \t 0.314s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.321s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.299s\n","loss =      0.00009 \t 0.278s\n","loss =      0.00009 \t 0.301s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.305s\n","loss =      0.00009 \t 0.319s\n","loss =      0.00009 \t 0.327s\n","loss =      0.00009 \t 0.282s\n","loss =      0.00009 \t 0.286s\n","loss =      0.00009 \t 0.289s\n","loss =      0.00009 \t 0.287s\n","loss =      0.00009 \t 0.303s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.306s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00009 \t 0.321s\n","loss =      0.00009 \t 0.312s\n","loss =      0.00009 \t 0.311s\n","loss =      0.00009 \t 0.306s\n","loss =      0.00009 \t 0.319s\n","loss =      0.00009 \t 0.322s\n","loss =      0.00009 \t 0.304s\n","loss =      0.00009 \t 0.315s\n","loss =      0.00009 \t 0.302s\n","loss =      0.00009 \t 0.310s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00009 \t 0.306s\n","loss =      0.00009 \t 0.322s\n","loss =      0.00009 \t 0.313s\n","loss =      0.00009 \t 0.314s\n","loss =      0.00009 \t 0.280s\n","loss =      0.00009 \t 0.316s\n","loss =      0.00009 \t 0.319s\n","loss =      0.00009 \t 0.317s\n","loss =      0.00009 \t 0.285s\n","loss =      0.00009 \t 0.291s\n","loss =      0.00009 \t 0.297s\n","loss =      0.00009 \t 0.281s\n","loss =      0.00009 \t 0.307s\n","loss =      0.00008 \t 0.317s\n","loss =      0.00009 \t 0.308s\n","loss =      0.00008 \t 0.311s\n","loss =      0.00008 \t 0.291s\n","loss =      0.00009 \t 0.286s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.307s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.307s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00008 \t 0.321s\n","loss =      0.00008 \t 0.321s\n","loss =      0.00008 \t 0.309s\n","loss =      0.00008 \t 0.311s\n","loss =      0.00008 \t 0.315s\n","loss =      0.00008 \t 0.319s\n","loss =      0.00008 \t 0.291s\n","loss =      0.00008 \t 0.319s\n","loss =      0.00008 \t 0.325s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00008 \t 0.473s\n","loss =      0.00008 \t 0.497s\n","loss =      0.00008 \t 0.304s\n","loss =      0.00008 \t 0.308s\n","loss =      0.00008 \t 0.321s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00008 \t 0.281s\n","loss =      0.00008 \t 0.294s\n","loss =      0.00008 \t 0.284s\n","loss =      0.00008 \t 0.319s\n","loss =      0.00008 \t 0.306s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00008 \t 0.293s\n","loss =      0.00008 \t 0.294s\n","loss =      0.00008 \t 0.306s\n","loss =      0.00008 \t 0.325s\n","loss =      0.00008 \t 0.309s\n","loss =      0.00008 \t 0.312s\n","loss =      0.00008 \t 0.321s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.312s\n","loss =      0.00008 \t 0.310s\n","loss =      0.00008 \t 0.316s\n","loss =      0.00008 \t 0.313s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.282s\n","loss =      0.00008 \t 0.313s\n","loss =      0.00008 \t 0.321s\n","loss =      0.00008 \t 0.292s\n","loss =      0.00008 \t 0.320s\n","loss =      0.00008 \t 0.311s\n","loss =      0.00008 \t 0.341s\n","loss =      0.00008 \t 0.313s\n","loss =      0.00008 \t 0.310s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00008 \t 0.333s\n","loss =      0.00008 \t 0.317s\n","loss =      0.00008 \t 0.307s\n","loss =      0.00008 \t 0.320s\n","loss =      0.00008 \t 0.306s\n","loss =      0.00008 \t 0.301s\n","loss =      0.00008 \t 0.297s\n","loss =      0.00008 \t 0.281s\n","loss =      0.00008 \t 0.302s\n","loss =      0.00008 \t 0.308s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.315s\n","loss =      0.00008 \t 0.285s\n","loss =      0.00008 \t 0.321s\n","loss =      0.00008 \t 0.312s\n","loss =      0.00008 \t 0.310s\n","loss =      0.00008 \t 0.315s\n","loss =      0.00008 \t 0.324s\n","loss =      0.00008 \t 0.306s\n","loss =      0.00008 \t 0.310s\n","loss =      0.00008 \t 0.332s\n","loss =      0.00008 \t 0.322s\n","loss =      0.00008 \t 0.277s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00008 \t 0.320s\n","loss =      0.00008 \t 0.306s\n","loss =      0.00008 \t 0.304s\n","loss =      0.00008 \t 0.315s\n","loss =      0.00008 \t 0.320s\n","loss =      0.00008 \t 0.311s\n","loss =      0.00008 \t 0.313s\n","loss =      0.00008 \t 0.323s\n","loss =      0.00008 \t 0.319s\n","loss =      0.00008 \t 0.304s\n","loss =      0.00008 \t 0.305s\n","loss =      0.00008 \t 0.323s\n","loss =      0.00008 \t 0.311s\n","loss =      0.00008 \t 0.288s\n","loss =      0.00008 \t 0.298s\n","loss =      0.00008 \t 0.288s\n","loss =      0.00008 \t 0.313s\n","loss =      0.00008 \t 0.297s\n","loss =      0.00008 \t 0.278s\n","loss =      0.00008 \t 0.310s\n","loss =      0.00008 \t 0.308s\n","loss =      0.00008 \t 0.314s\n","loss =      0.00008 \t 0.316s\n","loss =      0.00008 \t 0.312s\n","loss =      0.00008 \t 0.307s\n","loss =      0.00008 \t 0.313s\n","loss =      0.00008 \t 0.316s\n","loss =      0.00008 \t 0.315s\n","loss =      0.00008 \t 0.311s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.295s\n","loss =      0.00008 \t 0.318s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.318s\n","loss =      0.00007 \t 0.323s\n","loss =      0.00007 \t 0.286s\n","loss =      0.00008 \t 0.323s\n","loss =      0.00007 \t 0.299s\n","loss =      0.00007 \t 0.292s\n","loss =      0.00007 \t 0.279s\n","loss =      0.00007 \t 0.290s\n","loss =      0.00007 \t 0.281s\n","loss =      0.00007 \t 0.320s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00008 \t 0.306s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.308s\n","loss =      0.00007 \t 0.314s\n","loss =      0.00007 \t 0.329s\n","loss =      0.00007 \t 0.328s\n","loss =      0.00007 \t 0.310s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00007 \t 0.329s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.307s\n","loss =      0.00007 \t 0.308s\n","loss =      0.00007 \t 0.326s\n","loss =      0.00007 \t 0.292s\n","loss =      0.00007 \t 0.305s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.310s\n","loss =      0.00007 \t 0.309s\n","loss =      0.00007 \t 0.299s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00007 \t 0.305s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.324s\n","loss =      0.00007 \t 0.316s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.299s\n","loss =      0.00007 \t 0.285s\n","loss =      0.00007 \t 0.288s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.328s\n","loss =      0.00007 \t 0.328s\n","loss =      0.00007 \t 0.286s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00007 \t 0.287s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.291s\n","loss =      0.00007 \t 0.320s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.477s\n","loss =      0.00007 \t 0.482s\n","loss =      0.00007 \t 0.296s\n","loss =      0.00007 \t 0.290s\n","loss =      0.00007 \t 0.281s\n","loss =      0.00007 \t 0.285s\n","loss =      0.00007 \t 0.289s\n","loss =      0.00007 \t 0.281s\n","loss =      0.00007 \t 0.288s\n","loss =      0.00007 \t 0.288s\n","loss =      0.00007 \t 0.288s\n","loss =      0.00007 \t 0.292s\n","loss =      0.00007 \t 0.301s\n","loss =      0.00007 \t 0.275s\n","loss =      0.00007 \t 0.283s\n","loss =      0.00007 \t 0.310s\n","loss =      0.00007 \t 0.324s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.310s\n","loss =      0.00007 \t 0.316s\n","loss =      0.00007 \t 0.290s\n","loss =      0.00007 \t 0.283s\n","loss =      0.00007 \t 0.298s\n","loss =      0.00007 \t 0.314s\n","loss =      0.00007 \t 0.320s\n","loss =      0.00007 \t 0.323s\n","loss =      0.00007 \t 0.336s\n","loss =      0.00007 \t 0.281s\n","loss =      0.00007 \t 0.311s\n","loss =      0.00007 \t 0.346s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.284s\n","loss =      0.00007 \t 0.289s\n","loss =      0.00007 \t 0.286s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.311s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.320s\n","loss =      0.00007 \t 0.309s\n","loss =      0.00007 \t 0.307s\n","loss =      0.00007 \t 0.328s\n","loss =      0.00007 \t 0.339s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.318s\n","loss =      0.00007 \t 0.307s\n","loss =      0.00007 \t 0.310s\n","loss =      0.00007 \t 0.305s\n","loss =      0.00007 \t 0.336s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00007 \t 0.294s\n","loss =      0.00007 \t 0.291s\n","loss =      0.00007 \t 0.293s\n","loss =      0.00007 \t 0.307s\n","loss =      0.00007 \t 0.320s\n","loss =      0.00007 \t 0.311s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.307s\n","loss =      0.00007 \t 0.329s\n","loss =      0.00007 \t 0.316s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00007 \t 0.326s\n","loss =      0.00007 \t 0.325s\n","loss =      0.00007 \t 0.318s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.331s\n","loss =      0.00007 \t 0.330s\n","loss =      0.00007 \t 0.320s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.334s\n","loss =      0.00007 \t 0.331s\n","loss =      0.00007 \t 0.316s\n","loss =      0.00007 \t 0.326s\n","loss =      0.00007 \t 0.328s\n","loss =      0.00007 \t 0.318s\n","loss =      0.00007 \t 0.312s\n","loss =      0.00007 \t 0.327s\n","loss =      0.00007 \t 0.329s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.288s\n","loss =      0.00007 \t 0.314s\n","loss =      0.00007 \t 0.322s\n","loss =      0.00007 \t 0.309s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00007 \t 0.328s\n","loss =      0.00007 \t 0.338s\n","loss =      0.00007 \t 0.314s\n","loss =      0.00007 \t 0.289s\n","loss =      0.00007 \t 0.300s\n","loss =      0.00007 \t 0.316s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00007 \t 0.315s\n","loss =      0.00007 \t 0.331s\n","loss =      0.00007 \t 0.317s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00007 \t 0.313s\n","loss =      0.00007 \t 0.302s\n","loss =      0.00007 \t 0.321s\n","loss =      0.00006 \t 0.325s\n","loss =      0.00007 \t 0.318s\n","loss =      0.00006 \t 0.286s\n","loss =      0.00006 \t 0.315s\n","loss =      0.00007 \t 0.325s\n","loss =      0.00006 \t 0.325s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00007 \t 0.319s\n","loss =      0.00006 \t 0.334s\n","loss =      0.00006 \t 0.328s\n","loss =      0.00007 \t 0.314s\n","loss =      0.00006 \t 0.310s\n","loss =      0.00006 \t 0.330s\n","loss =      0.00006 \t 0.323s\n","loss =      0.00006 \t 0.313s\n","loss =      0.00006 \t 0.308s\n","loss =      0.00006 \t 0.316s\n","loss =      0.00006 \t 0.313s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.311s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.287s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.319s\n","loss =      0.00006 \t 0.323s\n","loss =      0.00006 \t 0.311s\n","loss =      0.00006 \t 0.316s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.310s\n","loss =      0.00006 \t 0.309s\n","loss =      0.00006 \t 0.318s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.309s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.295s\n","loss =      0.00006 \t 0.298s\n","loss =      0.00006 \t 0.293s\n","loss =      0.00006 \t 0.299s\n","loss =      0.00006 \t 0.281s\n","loss =      0.00006 \t 0.287s\n","loss =      0.00006 \t 0.301s\n","loss =      0.00006 \t 0.283s\n","loss =      0.00006 \t 0.320s\n","loss =      0.00006 \t 0.332s\n","loss =      0.00006 \t 0.298s\n","loss =      0.00006 \t 0.302s\n","loss =      0.00006 \t 0.445s\n","loss =      0.00006 \t 0.503s\n","loss =      0.00006 \t 0.303s\n","loss =      0.00006 \t 0.294s\n","loss =      0.00006 \t 0.285s\n","loss =      0.00006 \t 0.317s\n","loss =      0.00006 \t 0.336s\n","loss =      0.00006 \t 0.319s\n","loss =      0.00006 \t 0.320s\n","loss =      0.00006 \t 0.306s\n","loss =      0.00006 \t 0.299s\n","loss =      0.00006 \t 0.313s\n","loss =      0.00006 \t 0.305s\n","loss =      0.00006 \t 0.310s\n","loss =      0.00006 \t 0.316s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.312s\n","loss =      0.00006 \t 0.293s\n","loss =      0.00006 \t 0.318s\n","loss =      0.00006 \t 0.291s\n","loss =      0.00006 \t 0.317s\n","loss =      0.00006 \t 0.330s\n","loss =      0.00006 \t 0.289s\n","loss =      0.00006 \t 0.322s\n","loss =      0.00006 \t 0.332s\n","loss =      0.00006 \t 0.284s\n","loss =      0.00006 \t 0.284s\n","LBfgsOptimizerResults(converged=<tf.Tensor: shape=(), dtype=bool, numpy=False>, failed=<tf.Tensor: shape=(), dtype=bool, numpy=False>, num_iterations=<tf.Tensor: shape=(), dtype=int32, numpy=400>, num_objective_evaluations=<tf.Tensor: shape=(), dtype=int32, numpy=1173>, position=<tf.Tensor: shape=(4451,), dtype=float32, numpy=\n","array([ 0.10806289,  0.42420483, -0.28739768, ...,  0.01461153,\n","        0.01536485,  0.        ], dtype=float32)>, objective_value=<tf.Tensor: shape=(), dtype=float32, numpy=5.932867e-05>, objective_gradient=<tf.Tensor: shape=(4451,), dtype=float32, numpy=\n","array([ 1.05677522e-04, -1.36788745e-04,  9.31247414e-05, ...,\n","       -1.03223356e-04,  1.96820794e-04,  0.00000000e+00], dtype=float32)>, position_deltas=<tf.Tensor: shape=(10, 4451), dtype=float32, numpy=\n","array([[ 1.0915101e-05,  3.7580729e-05,  1.5079975e-05, ...,\n","         6.6617504e-06, -4.0307641e-05,  0.0000000e+00],\n","       [ 4.4181943e-06,  1.7255545e-05,  6.3776970e-06, ...,\n","         5.6782737e-06, -1.5391037e-05,  0.0000000e+00],\n","       [ 1.1444092e-05,  4.9978495e-05,  1.6301870e-05, ...,\n","         7.8268349e-06, -4.7096051e-05,  0.0000000e+00],\n","       ...,\n","       [ 9.5218420e-06,  4.2229891e-05,  1.9043684e-05, ...,\n","        -6.4447522e-07, -3.2716431e-05,  0.0000000e+00],\n","       [ 9.9539757e-06,  3.9815903e-05,  2.1308661e-05, ...,\n","         3.1283125e-06, -3.2673590e-05,  0.0000000e+00],\n","       [ 1.5191734e-05,  5.0306320e-05,  3.3259392e-05, ...,\n","         9.8170713e-06, -4.3178909e-05,  0.0000000e+00]], dtype=float32)>, gradient_deltas=<tf.Tensor: shape=(10, 4451), dtype=float32, numpy=\n","array([[-5.5257115e-06,  4.9104834e-05,  1.0326250e-04, ...,\n","        -5.4061221e-04, -2.0243530e-04,  0.0000000e+00],\n","       [-2.2104046e-05,  4.0557177e-05, -1.1967426e-05, ...,\n","         8.9765526e-04,  5.6326611e-04,  0.0000000e+00],\n","       [-6.5213128e-05,  1.5401667e-05,  3.6140569e-05, ...,\n","        -4.2803731e-04, -2.0786413e-04,  0.0000000e+00],\n","       ...,\n","       [ 1.6485927e-05,  8.3569321e-06,  1.1518088e-05, ...,\n","        -3.4604868e-04,  3.6368685e-05,  0.0000000e+00],\n","       [-2.9258084e-05, -7.2422881e-05,  8.4676387e-05, ...,\n","        -3.3054166e-05,  7.9655583e-05,  0.0000000e+00],\n","       [ 1.2033972e-04, -1.4074624e-04,  1.0134908e-04, ...,\n","         2.2921842e-05,  1.4711317e-04,  0.0000000e+00]], dtype=float32)>)\n"]}]},{"cell_type":"code","metadata":{"id":"5Z6WN9DFv1B2","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1658288053996,"user_tz":-540,"elapsed":7159,"user":{"displayName":"박민혁","userId":"04490186307398600319"}},"outputId":"43c01167-31e5-4963-ec6c-938b78471825"},"source":["def u(network,x,y,t):\n","    z = tf.convert_to_tensor([[x, y, t]])\n","    uvp = network(z)\n","    u = float(uvp[:,0])\n","    v = float(uvp[:,1])\n","    return u, v\n","\n","def exact_sol(x,y,t):\n","    Re = 100.0\n","    u = - math.cos(pi*x)*math.sin(pi*y)*math.exp(-2.0*pi*pi*t/Re)\n","    v = math.sin(pi*x)*math.cos(pi*y)*math.exp(-2.0*pi*pi*t/Re)\n","    return u, v\n","\n","P = data_test\n","\n","err = 0\n","for i in range(len(P)):\n","    u_pred, v_pred = u(PDEmodel, P[i][0], P[i][1], P[i][2])\n","    u_e, v_e = exact_sol(P[i][0], P[i][1], P[i][2])\n","    err += (u_pred - u_e)**2 + (v_pred - v_e)**2\n","    # if (i < 1000):\n","    # print(u_e)\n","    # print(u_pred)\n","    # print(\"-----\")\n","\n","L2 = math.sqrt(err/len(P))\n","print(\"L2 = \", L2)\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as mtick\n","losses = np.array(losses_hist)\n","losses = losses.reshape(len(losses))\n","epochs = losses.size\n","x_epochs = [i+1 for i in range(epochs)]\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot(x_epochs,losses, color = 'blue')\n","ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.2e'))\n","plt.setp(ax, xlabel='Iteration')\n","plt.setp(ax, ylabel='Loss')\n","plt.show()\n","\n","loss_file = open(\"Loss.txt\", \"w\")\n","for row in np.array(losses_hist).reshape(len(losses_hist), 1):\n","    np.savetxt(loss_file, row)\n","loss_file.close()"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["L2 =  0.0025707789779588655\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}