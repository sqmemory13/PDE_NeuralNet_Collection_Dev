{"cells":[{"cell_type":"markdown","source":["\n","Warning: This colab may not work if tensorflow version 1 support from colab is removed by google\n","\n","Source for port: https://github.com/guodongsanjianke/Neural-Network-for-solving-PDE\n"],"metadata":{"id":"WjxRfyIq_vFp"}},{"cell_type":"markdown","metadata":{"id":"x431BmA-8hvd"},"source":["# Deep Galerkin Method (DGM)\n","### S1 = sigma(w1*x + b1)  Z(l) = sigma(u*x + w*S + b) l=1,...,L  G(l) = sigma(u*x + w*S + b) l=1,...,L  \n","### R(l) = sigma(u*x + w*S + b) l=1,...,L   H(l) = sigma(u*x + w*(S Hadamard R) + b)  l=1,...,L  \n","### S(L+1) = (1-G) Hadamard H + Z Hadamard S  f = w*S(L+1) + b  "]},{"cell_type":"code","source":["%tensorflow_version 1.x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T5jrWjLa_Inz","executionInfo":{"status":"ok","timestamp":1658243108783,"user_tz":-540,"elapsed":7,"user":{"displayName":"박민혁","userId":"04490186307398600319"}},"outputId":"5598e22f-3caf-4bb1-b12e-ab75ef50b654"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n","After that, `%tensorflow_version 1.x` will throw an error.\n","\n","Your notebook should be updated to use Tensorflow 2.\n","See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n","\n","TensorFlow 1.x selected.\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LfTHJft08hvg","executionInfo":{"status":"ok","timestamp":1658243112046,"user_tz":-540,"elapsed":3267,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["#import needed packages\n","import tensorflow as tf\n","import numpy as np\n","import scipy as sp\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"CGnbLCj88hvi"},"source":["**input_dim:** dimensionality of imput data  \n","**output_dim:** number of output for LSTM layer  \n","**trans1, trans2 (str):** activation functions used inside the layer;  \n","one of: \"tanh\"(default), \"relu\" or \"sigmoid\"  \n","**u vectors:** weighting vectors for inputs original inputs x  \n","**w vectors:** weighting vectors for output of previous layer  \n","**S:** output of previous layer  \n","**X:** data input"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"OMzZUnf_8hvi","executionInfo":{"status":"ok","timestamp":1658243112046,"user_tz":-540,"elapsed":7,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["# LSTM-like layer used in DGM\n","class LSTMLayer(tf.keras.layers.Layer):\n","    \n","    # constructor/initializer function (automatically called when new instance of class is created)\n","    def __init__(self, output_dim, input_dim, trans1 = \"tanh\", trans2 = \"tanh\"):\n","        \n","        super(LSTMLayer, self).__init__()\n","        \n","        self.output_dim = output_dim\n","        self.input_dim = input_dim\n","        \n","        if trans1 == \"tanh\":\n","            self.trans1 = tf.nn.tanh\n","        elif trans1 == \"relu\":\n","            self.trans1 = tf.nn.relu\n","        elif trans1 == \"sigmoid\":\n","            self.trans1 = tf.nn.sigmoid\n","        \n","        if trans2 == \"tanh\":\n","            self.trans2 = tf.nn.tanh\n","        elif trans2 == \"relu\":\n","            self.trans2 = tf.nn.relu\n","        elif trans2 == \"sigmoid\":\n","            self.trans2 = tf.nn.relu\n","        \n","        # u vectors (weighting vectors for inputs original inputs x)\n","        self.Uz = self.add_variable(\"Uz\", shape=[self.input_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        self.Ug = self.add_variable(\"Ug\", shape=[self.input_dim ,self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        self.Ur = self.add_variable(\"Ur\", shape=[self.input_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        self.Uh = self.add_variable(\"Uh\", shape=[self.input_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        \n","        # w vectors (weighting vectors for output of previous layer)        \n","        self.Wz = self.add_variable(\"Wz\", shape=[self.output_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        self.Wg = self.add_variable(\"Wg\", shape=[self.output_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        self.Wr = self.add_variable(\"Wr\", shape=[self.output_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        self.Wh = self.add_variable(\"Wh\", shape=[self.output_dim, self.output_dim],\n","                                    initializer = tf.contrib.layers.xavier_initializer())\n","        \n","        # bias vectors\n","        self.bz = self.add_variable(\"bz\", shape=[1, self.output_dim])\n","        self.bg = self.add_variable(\"bg\", shape=[1, self.output_dim])\n","        self.br = self.add_variable(\"br\", shape=[1, self.output_dim])\n","        self.bh = self.add_variable(\"bh\", shape=[1, self.output_dim])\n","    \n","    \n","    def call(self, S, X):\n","\n","        Z = self.trans1(tf.add(tf.add(tf.matmul(X,self.Uz), tf.matmul(S,self.Wz)), self.bz))\n","        G = self.trans1(tf.add(tf.add(tf.matmul(X,self.Ug), tf.matmul(S, self.Wg)), self.bg))\n","        R = self.trans1(tf.add(tf.add(tf.matmul(X,self.Ur), tf.matmul(S, self.Wr)), self.br))\n","        \n","        H = self.trans2(tf.add(tf.add(tf.matmul(X,self.Uh), tf.matmul(tf.multiply(S, R), self.Wh)), self.bh))\n","        \n","        S_new = tf.add(tf.multiply(tf.subtract(tf.ones_like(G), G), H), tf.multiply(Z,S))\n","        \n","        return S_new"]},{"cell_type":"markdown","metadata":{"id":"2cslXZ4W8hvj"},"source":["**input_dim:** dimensionality of input data  \n","**output_dim:** number of outputs for dense layer  \n","**transformation:** activation function used inside the layer; using None is equivalent to the identity map  \n","**w vectors:** weighting vectors for output of previous layer  \n","**X:** input to layer  "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"dBzNixqV8hvk","executionInfo":{"status":"ok","timestamp":1658243112046,"user_tz":-540,"elapsed":6,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["# Fully connected layer(dense)\n","class DenseLayer(tf.keras.layers.Layer):\n","    \n","    # constructor/initializer function (automatically called when new instance of class is created)\n","    def __init__(self, output_dim, input_dim, transformation=None):\n","        \n","        super(DenseLayer,self).__init__()\n","        self.output_dim = output_dim\n","        self.input_dim = input_dim\n","\n","        self.W = self.add_variable(\"W\", shape=[self.input_dim, self.output_dim],\n","                                   initializer = tf.contrib.layers.xavier_initializer())\n","        \n","        # bias vectors\n","        self.b = self.add_variable(\"b\", shape=[1, self.output_dim])\n","        \n","        if transformation:\n","            if transformation == \"tanh\":\n","                self.transformation = tf.tanh\n","            elif transformation == \"relu\":\n","                self.transformation = tf.nn.relu\n","        else:\n","            self.transformation = transformation\n","    \n","    \n","    def call(self,X):\n","        \n","        S = tf.add(tf.matmul(X, self.W), self.b)\n","                \n","        if self.transformation:\n","            S = self.transformation(S)\n","        \n","        return S"]},{"cell_type":"markdown","metadata":{"id":"gD6FcvOM8hvk"},"source":["**n_layers:** number of intermediate LSTM layers  \n","**input_dim:** spaital dimension of input data (excludes time dimension)  \n","**final_trans:** transformation used in final layer\n","define initial layer as fully connected\n","to account for time inputs we use input_dim+1 as the input dimension\n","**t:** sampled time inputs  \n","**x:** sampled space inputs  \n","Run the DGM model and obtain fitted function value at the inputs (t,x)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"KFVT_3H88hvl","executionInfo":{"status":"ok","timestamp":1658243112636,"user_tz":-540,"elapsed":14,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["# Neural network architecture used in DGM\n","\n","class DGMNet(tf.keras.Model):\n","    \n","    def __init__(self, layer_width, n_layers, input_dim, final_trans=None):\n","        \n","        super(DGMNet,self).__init__()\n","        \n","        self.initial_layer = DenseLayer(layer_width, input_dim+1, transformation = \"tanh\")\n","        \n","        self.n_layers = n_layers\n","        self.LSTMLayerList = []\n","                \n","        for _ in range(self.n_layers):\n","            self.LSTMLayerList.append(LSTMLayer(layer_width, input_dim+1))\n","        \n","        self.final_layer = DenseLayer(1, layer_width, transformation = final_trans)\n","    \n","    def call(self,t,x):\n","\n","        X = tf.concat([t,x],1)\n","        \n","        # call initial layer\n","        S = self.initial_layer.call(X)\n","        \n","        # call intermediate LSTM layers\n","        for i in range(self.n_layers):\n","            S = self.LSTMLayerList[i].call(S,X)\n","        \n","        # call final LSTM layers\n","        result = self.final_layer.call(S)\n","        \n","        return result"]},{"cell_type":"markdown","metadata":{"id":"Xr8hcIHg8hvl"},"source":["Parameters"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"F_K7RwOB8hvm","executionInfo":{"status":"ok","timestamp":1658243112636,"user_tz":-540,"elapsed":14,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["# OU process parameters（Ornstein-Uhlenbeck Process）\n","kappa = 0\n","theta = 0.5\n","sigma = 2\n","\n","# mean and standard deviation for (normally distributed) process starting value\n","alpha = 0.0\n","beta = 1\n","\n","# tenminal time\n","T = 1.0\n","\n","# bounds of sampling region for space dimension, i.e. sampling will be done on\n","# [multipliter*Xlow, multiplier*Xhigh]\n","Xlow = -4.0\n","Xhigh = 4.0\n","x_multiplier = 2.0\n","t_multiplier = 1.5\n","\n","# neural network parameters\n","num_layers = 3\n","nodes_per_layer = 50\n","learning_rate = 0.001\n","\n","# Training parameters\n","sampling_stages = 500\n","steps_per_sample = 10\n","\n","# Sampling parameters\n","nSim_t = 5\n","nSim_x_interior = 50\n","nSim_x_initial = 50\n","\n","# Save options\n","saveName = 'FokkerPlanck'\n","saveFigure = False"]},{"cell_type":"markdown","metadata":{"id":"xphUoRO_8hvm"},"source":["**OU Simulation function(Ornstein-Uhlenbeck Process)**  \n","Simulate end point of Ornstein-Uhlenbeck process with normally distributed random starting value  \n","**alpha:** mean of random starting value  \n","**beta:** standard deviation of random starting value   \n","**theta:** mean reversion level    \n","**kappa:** mean reversion rate  \n","**sigma:** volatility  \n","**nSim:** number of simulations  \n","**T:** terminal time  "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"v9isZ6gb8hvm","executionInfo":{"status":"ok","timestamp":1658243112636,"user_tz":-540,"elapsed":13,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["def simulateOU_GaussianStart(alpha, beta, theta, kappa, sigma, nSim, T):\n","    \n","    # simulate initial point based on normal distribution\n","    X0 = np.random.normal(loc = alpha, scale = beta, size = nSim)\n","    \n","    # mean and variance of OU endpoint\n","    m = theta + (X0 - theta) * np.exp(-kappa * T)\n","    v = np.sqrt(sigma**2 / (2 * kappa) * (1 - np.exp(-2*kappa*T)))\n","    \n","    # simulate endpoint\n","    Xt = np.random.normal(m,v)    \n","    \n","    return Xt"]},{"cell_type":"markdown","metadata":{"id":"XN6JtyKu8hvn"},"source":["Sample time-space points from the function's domain;  \n","point are sampled uniformly on the interior of the domain, at the initial/terminal time points  \n","and along the spatial boundary at different time points.  \n","**nSim_t:** number of (interior) time points to sample  \n","**nSim_x_interior:** number of space points in the interior of the function's domain to sample  \n","**nSim_x_initial:** number of space points at initial time to sample (initial condition)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"4D87Z43l8hvn","executionInfo":{"status":"ok","timestamp":1658243112637,"user_tz":-540,"elapsed":14,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["# Sampling function - random sample time-space pairs\n","def sampler(nSim_t, nSim_x_interior, nSim_x_initial):\n","    \n","    # Sampler1: domain interior\n","    t = np.random.uniform(low=0, high=T*t_multiplier, size=[nSim_t, 1])\n","    x_interior = np.random.uniform(low=Xlow*x_multiplier, high=Xhigh*x_multiplier, size=[nSim_x_interior, 1])\n","    \n","    # Sampler: spatial boundary\n","    # no spatial boundary condition for this problem \n","    \n","    # Sampler3: initial/terminal condition\n","    x_initial = np.random.uniform(low=Xlow*1.5, high=Xhigh*1.5, size = [nSim_x_initial, 1])\n","    \n","    return t, x_interior, x_initial"]},{"cell_type":"markdown","metadata":{"id":"f6LfpEGe8hvn"},"source":["Compute total loss for training.     \n","The loss is based o the PDE satisfied by the negative-exponential of the density and NOT the density   \n","itself, i.e. the u(t,x) in p(t,x) = exp(-u(t,x)) / c(t) where p is the density and c is the normalization constant.    \n","**model:** DGM model object   \n","**t:** sampled (interior) time points  \n","**x_interior:** sampled space points in the interior of the function's domain   \n","**x_initial:** sampled space points at initial time   \n","**nSim_t:** number of (interior) time points sampled (size of t)  \n","**alpha:** mean of normal distribution for process staring value  \n","**beta:** standard deviation of normal distribution for process starting value  \n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"LbX4Eqam8hvn","executionInfo":{"status":"ok","timestamp":1658243112637,"user_tz":-540,"elapsed":14,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":["# Loss function for Fokker-Planck equation\n","\n","def loss(model, t, x_interior, x_initial, nSim_t, alpha, beta):\n","    \n","    # Loss term1: PDE\n","    \n","    # initialize vector of losses\n","    losses_u = []\n","    \n","    # for each simulated interior time point\n","    for tIndex in range(nSim_t):\n","        \n","        curr_t = t[tIndex]\n","        t_vector = curr_t * tf.ones_like(x_interior)\n","        \n","        u    = model.call(t_vector, x_interior)\n","        u_t  = tf.gradients(u, t_vector)[0]\n","        u_x  = tf.gradients(u, x_interior)[0]\n","        u_xx = tf.gradients(u_x, x_interior)[0]\n","\n","        psi_denominator = tf.reduce_sum(tf.exp(-u))\n","        psi = tf.reduce_sum( u_t*tf.exp(-u) ) / psi_denominator\n","\n","        # PDE differential operator\n","        diff_f = -u_t + kappa - kappa*(x_interior- theta)*u_x - 0.5*sigma**2*(-u_xx + u_x**2) + psi\n","        \n","        # compute L2-norm of differential operator and attach to vector of losses\n","        currLoss = tf.reduce_mean(tf.square(diff_f)) \n","        losses_u.append(currLoss)\n","    \n","    # average losses across sample time points \n","    L1 = tf.add_n(losses_u) / nSim_t\n","    \n","    # Loss term2: boundary condition\n","    # no boundary condition for this problem\n","    \n","    # Loss term3: initial condition\n","    # compute negative-exponential of neural network-implied pdf at t = 0 i.e. the u in p = e^[-u(t,x)] / c(t)\n","    fitted_pdf = model.call(0*tf.ones_like(x_initial), x_initial)\n","    \n","    target_pdf  = 0.5*(x_initial - alpha)**2 / (beta**2)\n","    \n","    # average L2 error for initial distribution\n","    L3 = tf.reduce_mean(tf.square(fitted_pdf - target_pdf))\n","\n","    return L1, L3"]},{"cell_type":"markdown","metadata":{"id":"_i-MHbfb8hvo"},"source":["##### input(time, space domain interior, space domain at initial time)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a1ymBAUh8hvo","executionInfo":{"status":"ok","timestamp":1658243164362,"user_tz":-540,"elapsed":51739,"user":{"displayName":"박민혁","userId":"04490186307398600319"}},"outputId":"34914025-c4bd-4d1d-b992-b9c855121c8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-4-20dd6a9ad24e>:12: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"]}],"source":["# Set up network\n","model = DGMNet(nodes_per_layer, num_layers, 1)\n","\n","t_tnsr = tf.placeholder(tf.float32, [None,1])\n","x_interior_tnsr = tf.placeholder(tf.float32, [None,1])\n","x_initial_tnsr = tf.placeholder(tf.float32, [None,1])\n","\n","# loss \n","L1_tnsr, L3_tnsr = loss(model, t_tnsr, x_interior_tnsr, x_initial_tnsr, nSim_t, alpha, beta)\n","loss_tnsr = L1_tnsr + L3_tnsr\n","\n","u = model.call(t_tnsr, x_interior_tnsr)\n","p_unnorm = tf.exp(-u)\n","\n","# set optimizer\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_tnsr)\n","\n","# initialize variables\n","init_op = tf.global_variables_initializer()\n","\n","# open session\n","sess = tf.Session()\n","sess.run(init_op)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFua8Sj78hvo","executionInfo":{"status":"ok","timestamp":1658244167482,"user_tz":-540,"elapsed":1003123,"user":{"displayName":"박민혁","userId":"04490186307398600319"}},"outputId":"924b8608-e41a-4e23-b650-6b72e690333d"},"outputs":[{"output_type":"stream","name":"stdout","text":["22.812868 5.436423 17.376446 0\n","10.718926 2.5900948 8.128832 1\n","4.222125 2.3220575 1.9000678 2\n","5.185042 1.5877342 3.5973077 3\n","2.230497 0.79645437 1.4340425 4\n","1.4961798 0.21687324 1.2793065 5\n","0.9004463 0.15370221 0.7467441 6\n","2.8749466 1.8999363 0.9750103 7\n","5.5001974 3.116194 2.3840034 8\n","3.5943904 1.9488782 1.6455123 9\n","1.2869014 0.36830148 0.91859984 10\n","1.7028573 0.7882127 0.9146446 11\n","0.6928726 0.07769261 0.61517996 12\n","1.0116818 0.40945527 0.6022265 13\n","0.36748284 0.064212315 0.30327052 14\n","1.318481 0.66494864 0.65353227 15\n","1.3227687 0.4206755 0.9020932 16\n","1.9980757 1.3705178 0.62755793 17\n","0.925474 0.53773135 0.38774264 18\n","0.5125839 0.15491436 0.35766953 19\n","0.43031222 0.22688413 0.20342807 20\n","0.47286168 0.100831866 0.3720298 21\n","0.33298072 0.22121067 0.11177004 22\n","0.29282647 0.12803052 0.16479595 23\n","0.113614395 0.02909561 0.08451878 24\n","0.1086739 0.063285016 0.04538889 25\n","0.80649495 0.44755998 0.35893497 26\n","0.38746822 0.15356258 0.23390564 27\n","0.15997104 0.06923182 0.09073922 28\n","1.2749097 0.9013137 0.37359604 29\n","0.49482146 0.098887585 0.39593387 30\n","0.5043572 0.3293317 0.17502552 31\n","0.30263475 0.12917478 0.17345996 32\n","0.27540964 0.12952745 0.14588219 33\n","0.08104594 0.051247936 0.029798009 34\n","0.11592132 0.052136797 0.063784525 35\n","0.10218755 0.031164164 0.07102339 36\n","0.7864749 0.35503298 0.4314419 37\n","0.8181085 0.3108406 0.5072679 38\n","0.33106628 0.088533506 0.24253277 39\n","0.22635837 0.043231692 0.18312667 40\n","0.9521321 0.44963083 0.50250125 41\n","0.43864638 0.1335196 0.30512676 42\n","0.32182786 0.20198475 0.1198431 43\n","0.14394301 0.078695096 0.06524792 44\n","0.20702796 0.10808613 0.098941825 45\n","0.25591382 0.14015505 0.11575877 46\n","0.08872894 0.01936003 0.069368914 47\n","0.15503678 0.09098578 0.06405099 48\n","0.2075893 0.13115685 0.07643246 49\n","0.12320569 0.09580221 0.02740348 50\n","0.11202175 0.06592296 0.04609879 51\n","0.04203178 0.025307292 0.01672449 52\n","0.1433065 0.09570725 0.047599234 53\n","0.054499008 0.031194229 0.02330478 54\n","0.051324166 0.017036108 0.03428806 55\n","0.024601754 0.014720744 0.009881008 56\n","0.7015054 0.6117211 0.089784294 57\n","0.1987721 0.1166408 0.08213131 58\n","0.06266454 0.029069576 0.033594962 59\n","0.5185081 0.38759854 0.13090953 60\n","0.3014184 0.11350458 0.18791382 61\n","0.13974014 0.06416741 0.07557272 62\n","0.1894462 0.1521873 0.037258893 63\n","0.10847406 0.06337211 0.045101948 64\n","0.031400785 0.018293113 0.013107674 65\n","0.06473398 0.052258123 0.0124758575 66\n","0.142011 0.08007314 0.061937865 67\n","0.06547919 0.027874876 0.037604317 68\n","0.08584219 0.040840764 0.045001425 69\n","0.0294886 0.012875273 0.016613329 70\n","0.033299938 0.013788446 0.019511491 71\n","0.010459898 0.0069383583 0.0035215393 72\n","0.08016913 0.06350111 0.01666801 73\n","0.03292237 0.010098078 0.02282429 74\n","0.029485531 0.008216622 0.02126891 75\n","0.38708478 0.25282618 0.13425861 76\n","0.27941686 0.06955 0.20986687 77\n","0.12160544 0.026909376 0.09469607 78\n","0.05540634 0.015417081 0.03998926 79\n","0.19329718 0.116928175 0.076369 80\n","0.041616805 0.020280452 0.02133635 81\n","0.07533075 0.030345147 0.044985604 82\n","0.04479012 0.028200913 0.016589208 83\n","0.018368933 0.008438537 0.009930397 84\n","0.027550034 0.020124549 0.0074254856 85\n","0.15048997 0.13400419 0.016485786 86\n","0.12199826 0.10707133 0.014926923 87\n","0.060343623 0.04482066 0.015522964 88\n","0.024347464 0.0137251755 0.010622288 89\n","0.020633455 0.01407553 0.0065579247 90\n","0.02772585 0.012842834 0.014883015 91\n","0.022208825 0.012802941 0.009405884 92\n","0.03252414 0.025870359 0.006653781 93\n","0.016482381 0.01054833 0.005934051 94\n","0.01630224 0.008279607 0.0080226315 95\n","0.011890082 0.0065710554 0.0053190268 96\n","0.0058744983 0.00222765 0.0036468483 97\n","0.0118131265 0.00793418 0.003878946 98\n","0.07654174 0.05605035 0.02049139 99\n","0.03374876 0.020761121 0.012987641 100\n","0.048142243 0.028078718 0.020063525 101\n","0.013646917 0.010170026 0.003476892 102\n","0.023718819 0.014223735 0.009495083 103\n","0.01743659 0.007872763 0.009563826 104\n","0.012370294 0.0065153213 0.005854972 105\n","0.007537735 0.004574526 0.002963209 106\n","0.5141107 0.4645663 0.04954437 107\n","0.13985592 0.03997454 0.09988137 108\n","0.016779423 0.011763747 0.005015676 109\n","0.39563638 0.2528953 0.14274108 110\n","0.054021902 0.021910932 0.03211097 111\n","0.087293334 0.038187046 0.04910629 112\n","0.045205384 0.021072721 0.024132662 113\n","0.045822352 0.03477318 0.011049173 114\n","0.0722391 0.033946883 0.038292218 115\n","0.049849547 0.025691522 0.024158023 116\n","0.04119475 0.03679238 0.0044023735 117\n","0.047610633 0.013453148 0.034157485 118\n","0.027355999 0.012417884 0.014938116 119\n","0.015763218 0.0073934007 0.008369817 120\n","1.7058351 1.2636243 0.44221073 121\n","0.4611448 0.15545659 0.3056882 122\n","0.36185926 0.20502715 0.15683211 123\n","0.7635779 0.42295834 0.34061953 124\n","0.3676861 0.23802541 0.12966067 125\n","0.23119307 0.116258696 0.11493437 126\n","0.07019116 0.028363887 0.04182727 127\n","0.11325303 0.050546765 0.06270626 128\n","0.06335774 0.016238168 0.04711957 129\n","0.03558536 0.010562262 0.025023097 130\n","0.40562832 0.19992125 0.20570706 131\n","0.21362944 0.1374865 0.07614294 132\n","0.07238862 0.023589488 0.048799135 133\n","0.123751685 0.06909322 0.054658465 134\n","0.07988512 0.049547315 0.030337805 135\n","0.06790821 0.01714674 0.050761476 136\n","0.25302622 0.21805175 0.03497447 137\n","0.119875595 0.047339316 0.072536275 138\n","0.11568877 0.056375008 0.05931376 139\n","0.03204753 0.017726272 0.0143212555 140\n","0.040819243 0.028326873 0.012492368 141\n","0.045377165 0.012992444 0.03238472 142\n","0.08235547 0.027393565 0.054961905 143\n","0.045079585 0.031580087 0.013499498 144\n","0.010742044 0.006211434 0.00453061 145\n","0.031306267 0.023581168 0.007725101 146\n","0.02005275 0.011078835 0.008973914 147\n","0.08510018 0.07429958 0.0108006 148\n","0.054403804 0.04433511 0.010068698 149\n","0.023542356 0.018290926 0.0052514304 150\n","0.013291658 0.008420651 0.004871007 151\n","0.30573344 0.16157977 0.14415365 152\n","0.17008933 0.14938214 0.020707197 153\n","0.11881291 0.088324755 0.030488158 154\n","0.04898169 0.02728855 0.021693137 155\n","0.08486728 0.0661335 0.018733783 156\n","0.13597542 0.10880655 0.027168876 157\n","0.025334077 0.011787349 0.013546728 158\n","0.041311093 0.02599563 0.015315464 159\n","0.041138288 0.030713547 0.010424741 160\n","0.017357206 0.010031259 0.0073259473 161\n","0.0572137 0.029715354 0.027498346 162\n","0.015596429 0.008153862 0.0074425666 163\n","0.008732246 0.0017757731 0.006956473 164\n","0.00935935 0.0044482 0.00491115 165\n","0.007061461 0.0058996985 0.0011617624 166\n","0.009493029 0.007128436 0.0023645922 167\n","0.011360851 0.007615555 0.003745296 168\n","0.010664642 0.0071064727 0.0035581691 169\n","0.0032774312 0.0017033191 0.0015741122 170\n","0.0043196217 0.0027685107 0.001551111 171\n","0.053205825 0.03780606 0.015399763 172\n","0.020532437 0.013376576 0.007155861 173\n","0.53828347 0.2162447 0.3220388 174\n","0.13727562 0.049504388 0.08777124 175\n","0.078759514 0.06083705 0.017922467 176\n","0.05271101 0.02698849 0.025722522 177\n","0.31277 0.18956438 0.12320562 178\n","0.16118121 0.118155055 0.04302616 179\n","0.06589976 0.030981554 0.034918204 180\n","0.10122666 0.06078398 0.040442683 181\n","0.31453788 0.15286282 0.16167505 182\n","0.10252205 0.05795374 0.04456831 183\n","0.4019455 0.23509137 0.16685413 184\n","0.085379034 0.03781572 0.04756331 185\n","0.78679645 0.33263755 0.4541589 186\n","0.25545114 0.19097713 0.064474 187\n","0.1188557 0.04852782 0.070327885 188\n","0.09650259 0.051535018 0.04496757 189\n","0.12812483 0.06813851 0.059986323 190\n","0.025494462 0.012021266 0.013473196 191\n","0.05012711 0.011788815 0.038338296 192\n","0.023857955 0.004369232 0.019488722 193\n","0.050515614 0.03270939 0.017806225 194\n","0.056443706 0.02622109 0.030222617 195\n","0.027054355 0.016220272 0.010834082 196\n","0.11748827 0.10833397 0.009154307 197\n","0.03437298 0.02565991 0.008713071 198\n","0.06858412 0.039636638 0.028947482 199\n","0.104409434 0.07512737 0.029282061 200\n","0.46810627 0.32975325 0.13835302 201\n","0.27706575 0.20641604 0.07064973 202\n","0.12366961 0.04995582 0.07371379 203\n","0.054401383 0.013002092 0.041399293 204\n","0.066603534 0.027635885 0.03896765 205\n","0.07424537 0.023053424 0.05119195 206\n","0.035035387 0.024727298 0.01030809 207\n","0.06017281 0.027923629 0.032249182 208\n","0.05104857 0.030120254 0.020928316 209\n","0.07677415 0.046223972 0.030550174 210\n","0.09229567 0.073338 0.018957669 211\n","0.035698984 0.012702105 0.022996878 212\n","0.015149615 0.009891502 0.005258113 213\n","0.012210997 0.007439796 0.0047712014 214\n","0.06682387 0.03171356 0.03511031 215\n","0.049708426 0.033389457 0.01631897 216\n","0.06392397 0.051588666 0.0123353 217\n","0.04303037 0.018050637 0.024979733 218\n","0.0168898 0.0094143 0.007475499 219\n","0.035476483 0.032988112 0.0024883696 220\n","0.008702208 0.0039519123 0.004750296 221\n","0.082245484 0.063222215 0.019023273 222\n","0.03859188 0.03498323 0.0036086503 223\n","0.06023545 0.049916398 0.010319051 224\n","0.03122326 0.023870474 0.0073527857 225\n","0.013707703 0.010674694 0.003033009 226\n","0.013888429 0.0078325765 0.0060558524 227\n","0.09260165 0.07286144 0.019740209 228\n","0.041204207 0.030075854 0.011128354 229\n","0.012349186 0.006474043 0.005875144 230\n","0.012227165 0.0038603717 0.008366793 231\n","0.018184295 0.011225297 0.0069589973 232\n","0.05921689 0.0515777 0.0076391925 233\n","0.2857714 0.24494815 0.040823244 234\n","0.07440728 0.02768594 0.046721336 235\n","0.037501633 0.013698444 0.023803191 236\n","1.4685853 0.8662615 0.6023237 237\n","1.7212293 1.0196705 0.70155877 238\n","0.452561 0.13935772 0.31320328 239\n","0.13767035 0.02988602 0.10778433 240\n","0.45021337 0.33878243 0.11143095 241\n","0.24874178 0.088694654 0.16004711 242\n","0.6736984 0.27290875 0.40078965 243\n","0.26775545 0.060643364 0.20711209 244\n","0.1614419 0.024641663 0.13680024 245\n","0.3782271 0.21816027 0.16006686 246\n","0.22084396 0.1422717 0.07857226 247\n","0.14352444 0.055761635 0.08776281 248\n","0.15517151 0.0735387 0.081632815 249\n","0.15432876 0.07101734 0.08331143 250\n","0.03505545 0.015344289 0.019711161 251\n","0.06756469 0.025237966 0.042326722 252\n","0.0867375 0.057258945 0.02947855 253\n","0.065645166 0.03850121 0.027143955 254\n","0.12251246 0.07763229 0.04488017 255\n","0.03455501 0.010107807 0.024447203 256\n","0.24616909 0.2082926 0.03787649 257\n","0.07366899 0.007014967 0.06665402 258\n","0.019381952 0.0071116462 0.012270305 259\n","0.25443783 0.20862353 0.045814313 260\n","0.23759694 0.18027365 0.05732329 261\n","0.12137903 0.035756562 0.085622475 262\n","0.14574255 0.045637634 0.10010492 263\n","0.16841897 0.13654558 0.031873398 264\n","0.49036434 0.38413948 0.10622487 265\n","0.37949038 0.28876343 0.09072694 266\n","0.098464735 0.062230285 0.03623445 267\n","0.058103226 0.031941414 0.026161814 268\n","0.038747907 0.018902594 0.019845312 269\n","0.06900034 0.053092387 0.015907953 270\n","0.33787787 0.13540283 0.20247506 271\n","0.108329244 0.029986208 0.078343034 272\n","0.048292924 0.036545005 0.011747918 273\n","0.13074473 0.114855625 0.015889108 274\n","0.013578115 0.007219851 0.006358264 275\n","0.030834215 0.020996219 0.009837996 276\n","0.0146323405 0.010949216 0.0036831247 277\n","0.091294944 0.040084567 0.05121038 278\n","0.027931748 0.015397325 0.012534423 279\n","0.038475983 0.02792413 0.010551851 280\n","0.07085242 0.05548525 0.015367172 281\n","0.07600649 0.058985915 0.017020574 282\n","0.077957265 0.057341266 0.020615997 283\n","0.017078925 0.0070190965 0.010059829 284\n","0.02465614 0.014258404 0.010397735 285\n","0.013914349 0.010020043 0.003894306 286\n","0.0058792187 0.004012533 0.0018666857 287\n","0.026966989 0.024558475 0.0024085138 288\n","0.013511352 0.007584225 0.005927128 289\n","0.04349702 0.026921345 0.016575672 290\n","0.07620313 0.06776734 0.008435796 291\n","0.086421646 0.065327846 0.021093803 292\n","0.032927815 0.011019657 0.021908158 293\n","0.07509439 0.034156162 0.040938225 294\n","0.030899107 0.015904179 0.014994929 295\n","0.06111805 0.03904448 0.022073573 296\n","0.020748723 0.007551037 0.0131976865 297\n","0.17403719 0.068870805 0.105166376 298\n","0.062466912 0.038624223 0.023842687 299\n","0.026411941 0.011005001 0.01540694 300\n","0.069285125 0.04868422 0.020600908 301\n","0.06830275 0.047982965 0.020319786 302\n","0.06326366 0.03646589 0.026797771 303\n","0.036184445 0.02032203 0.015862416 304\n","0.02445477 0.01909244 0.0053623305 305\n","0.0238274 0.014088827 0.009738572 306\n","0.0133876875 0.009323199 0.004064488 307\n","0.007773906 0.0032524832 0.0045214226 308\n","0.04411394 0.037136357 0.006977585 309\n","0.015754584 0.007846013 0.007908572 310\n","0.011409945 0.004928868 0.006481077 311\n","0.06679787 0.042441763 0.024356108 312\n","0.045701377 0.016501402 0.029199975 313\n","0.040372774 0.027788294 0.01258448 314\n","0.032854155 0.024228374 0.008625782 315\n","0.030844357 0.022451146 0.008393212 316\n","0.01764964 0.013454022 0.004195617 317\n","0.07120482 0.06809773 0.0031070835 318\n","0.032032885 0.02711599 0.0049168947 319\n","0.017560568 0.010571254 0.0069893124 320\n","0.013506426 0.010339794 0.0031666318 321\n","0.004031117 0.0013672452 0.0026638717 322\n","0.02565386 0.0126615185 0.012992341 323\n","0.019550417 0.00939935 0.010151067 324\n","0.0047508907 0.0015783785 0.0031725124 325\n","0.007172023 0.0014304201 0.0057416027 326\n","0.0061617177 0.002411267 0.0037504507 327\n","0.0413299 0.03817431 0.0031555945 328\n","0.008554813 0.0066161947 0.0019386187 329\n","0.049868323 0.043387443 0.0064808787 330\n","0.1146725 0.10748114 0.007191358 331\n","0.029113734 0.012622312 0.016491422 332\n","0.05244369 0.03564626 0.016797429 333\n","0.32463694 0.25570214 0.0689348 334\n","0.08769414 0.05345867 0.034235466 335\n","0.028572569 0.013639621 0.014932947 336\n","0.030869922 0.017572798 0.013297124 337\n","0.027795373 0.018975163 0.00882021 338\n","0.037041917 0.022405839 0.014636078 339\n","0.048898205 0.03709523 0.011802974 340\n","0.015819114 0.010330277 0.005488838 341\n","0.017194428 0.00454981 0.012644618 342\n","0.03173598 0.027767552 0.003968428 343\n","0.014504377 0.00899295 0.005511426 344\n","0.009775143 0.006472006 0.0033031376 345\n","0.011704858 0.0098870685 0.0018177896 346\n","0.015638053 0.008201069 0.007436985 347\n","0.0193142 0.011523739 0.0077904607 348\n","0.008178624 0.0054068244 0.0027718002 349\n","0.0077148667 0.0058959797 0.0018188868 350\n","0.009709257 0.008011211 0.0016980463 351\n","0.013109801 0.010546245 0.0025635564 352\n","0.025567327 0.021372423 0.0041949037 353\n","0.03736201 0.035073962 0.0022880486 354\n","0.01696978 0.008602059 0.00836772 355\n","0.034251608 0.029509893 0.004741716 356\n","0.04476592 0.031635508 0.013130411 357\n","0.029871194 0.027407277 0.002463917 358\n","0.012456115 0.009806332 0.0026497827 359\n","0.08698571 0.071360424 0.015625287 360\n","0.01345773 0.005329015 0.008128716 361\n","0.01229701 0.00960049 0.0026965197 362\n","0.055880588 0.044619393 0.011261196 363\n","0.14981654 0.13259493 0.01722161 364\n","0.014732007 0.0034451874 0.011286819 365\n","0.012525201 0.0025987953 0.009926406 366\n","0.035401963 0.017413499 0.017988466 367\n","0.0061838757 0.004258281 0.0019255946 368\n","0.01687051 0.010631851 0.00623866 369\n","0.027887726 0.02112405 0.006763676 370\n","0.019663475 0.016368635 0.0032948407 371\n","0.01071216 0.004106589 0.00660557 372\n","0.011671409 0.003919024 0.007752385 373\n","0.035038427 0.02617277 0.008865655 374\n","0.017263148 0.0052965297 0.011966619 375\n","0.11246179 0.096996926 0.015464867 376\n","0.016368791 0.007391208 0.008977584 377\n","0.007861111 0.0026662645 0.005194847 378\n","0.008364213 0.0068607004 0.0015035119 379\n","0.0073960423 0.005977116 0.0014189264 380\n","0.0048207873 0.0037220344 0.0010987531 381\n","0.015179455 0.010441682 0.004737773 382\n","0.023935389 0.020063927 0.0038714618 383\n","0.023784872 0.021285212 0.0024996595 384\n","0.06133244 0.035773154 0.025559284 385\n","0.019325513 0.015495238 0.0038302762 386\n","0.023041658 0.017121864 0.005919793 387\n","0.007901292 0.0025330645 0.005368228 388\n","0.039821588 0.023361167 0.016460422 389\n","0.01964443 0.011340727 0.008303703 390\n","0.06869679 0.01575153 0.05294526 391\n","0.049456313 0.044440344 0.0050159674 392\n","0.028072339 0.021661872 0.0064104665 393\n","0.08154832 0.07122069 0.010327626 394\n","0.044044398 0.034601312 0.009443084 395\n","0.02394183 0.018757027 0.005184802 396\n","0.021133829 0.01950194 0.0016318904 397\n","0.012584804 0.008516334 0.0040684696 398\n","0.0041470346 0.002951442 0.0011955927 399\n","0.012289049 0.009936095 0.002352954 400\n","0.02166808 0.019500932 0.0021671492 401\n","0.012772896 0.009168908 0.0036039886 402\n","0.0262641 0.022116197 0.0041479017 403\n","0.017735327 0.012371371 0.005363956 404\n","0.053072084 0.044663567 0.008408518 405\n","0.01638252 0.01186673 0.0045157894 406\n","0.009404037 0.0076434985 0.0017605391 407\n","0.27370742 0.09188152 0.1818259 408\n","0.21061441 0.12859948 0.082014926 409\n","0.09362772 0.054039795 0.03958793 410\n","0.056364175 0.02344603 0.032918144 411\n","0.18579283 0.11319577 0.07259706 412\n","0.08158562 0.010528757 0.071056865 413\n","0.016725315 0.0045961407 0.012129174 414\n","0.32303864 0.2307798 0.09225883 415\n","0.05339318 0.024890734 0.028502448 416\n","0.09660284 0.08434899 0.0122538535 417\n","0.026858475 0.013667784 0.013190691 418\n","0.043317012 0.018534219 0.024782792 419\n","0.017167363 0.011867307 0.005300057 420\n","0.018378595 0.015450495 0.0029280991 421\n","0.16440621 0.12060821 0.043798007 422\n","0.044887923 0.013405661 0.03148226 423\n","0.022422316 0.008300178 0.014122138 424\n","0.28487137 0.119808316 0.16506305 425\n","0.044148024 0.037632514 0.006515509 426\n","0.092854306 0.05532315 0.037531152 427\n","0.035336804 0.021683257 0.013653547 428\n","0.016488235 0.0076254206 0.008862814 429\n","0.010373222 0.0048048175 0.005568404 430\n","0.05636033 0.034147732 0.022212598 431\n","0.20916492 0.18795528 0.021209646 432\n","0.04423983 0.027486464 0.016753366 433\n","0.07898179 0.053363133 0.025618657 434\n","0.026522473 0.020667775 0.0058546984 435\n","0.008528055 0.005010714 0.003517341 436\n","0.005225027 0.0039762254 0.0012488018 437\n","0.005677469 0.0041622045 0.0015152649 438\n","0.0036880262 0.0022699775 0.0014180487 439\n","0.0031850855 0.0012261436 0.001958942 440\n","0.012158961 0.00955915 0.002599811 441\n","0.009096704 0.007309059 0.0017876456 442\n","0.054937378 0.05019355 0.0047438294 443\n","0.084040135 0.05074147 0.033298664 444\n","0.046632394 0.019505054 0.027127342 445\n","0.037213724 0.023778811 0.013434914 446\n","0.018871244 0.01278045 0.0060907938 447\n","0.08080648 0.0390571 0.04174938 448\n","0.038015705 0.021747919 0.016267786 449\n","0.05910467 0.048866898 0.010237772 450\n","0.093073405 0.024710143 0.068363264 451\n","0.029288813 0.016110478 0.013178336 452\n","0.009838771 0.00525487 0.0045839013 453\n","0.008362234 0.0044368384 0.0039253957 454\n","0.13692439 0.063237906 0.07368649 455\n","0.11454347 0.026625246 0.08791822 456\n","0.043100435 0.012243002 0.030857433 457\n","0.02066195 0.009494181 0.011167769 458\n","0.50407225 0.4740591 0.03001313 459\n","0.11602655 0.06417947 0.051847078 460\n","0.045511715 0.02260478 0.022906933 461\n","0.036167007 0.020117817 0.01604919 462\n","0.027647283 0.018207017 0.009440266 463\n","0.01722157 0.007930037 0.009291532 464\n","0.22085842 0.08048129 0.14037713 465\n","0.012542073 0.005969945 0.006572128 466\n","0.016892867 0.012201264 0.0046916036 467\n","0.031475086 0.019164449 0.012310636 468\n","0.10982574 0.07890095 0.030924788 469\n","0.028053556 0.010951824 0.017101733 470\n","0.082372226 0.06855153 0.013820692 471\n","0.047404654 0.03647694 0.010927713 472\n","0.045164213 0.036841575 0.008322638 473\n","0.014029444 0.009306214 0.0047232304 474\n","0.056455933 0.04087342 0.015582511 475\n","0.024880238 0.015221382 0.009658856 476\n","0.008594359 0.0024089466 0.0061854124 477\n","0.22990823 0.18718944 0.04271879 478\n","0.013510777 0.0074585783 0.006052198 479\n","0.045860246 0.026503349 0.019356899 480\n","0.017488096 0.011024503 0.006463593 481\n","0.042429052 0.03213337 0.010295681 482\n","0.019805415 0.011940826 0.007864589 483\n","0.007257471 0.004298852 0.0029586188 484\n","0.010684 0.007863485 0.0028205153 485\n","0.00408231 0.0031932765 0.00088903337 486\n","0.005662066 0.0034267113 0.0022353549 487\n","0.23299411 0.18479668 0.048197433 488\n","0.04041289 0.025822533 0.014590358 489\n","0.11086087 0.072745346 0.03811552 490\n","0.059360817 0.010578392 0.048782423 491\n","0.027293483 0.0073910602 0.019902423 492\n","0.0116162645 0.0057766223 0.005839642 493\n","0.034133878 0.021076895 0.013056981 494\n","0.024858832 0.02102912 0.0038297111 495\n","0.016252415 0.011187212 0.005065203 496\n","0.017661087 0.01629952 0.0013615682 497\n","0.012035377 0.0064426884 0.005592689 498\n","0.014618836 0.013580419 0.0010384176 499\n"]}],"source":["#Train network\n","for i in range(sampling_stages):\n","    \n","    # sample uniformly from the required regions\n","    t, x_interior, x_initial = sampler(nSim_t, nSim_x_interior, nSim_x_initial)\n","    \n","    for j in range(steps_per_sample):\n","        loss,L1,L3,_ = sess.run([loss_tnsr, L1_tnsr, L3_tnsr, optimizer],\n","                                feed_dict = {t_tnsr:t, x_interior_tnsr:x_interior, x_initial_tnsr:x_initial})\n","        \n","    print(loss, L1, L3, i)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"8SED-CAp8hvo","executionInfo":{"status":"ok","timestamp":1658244172231,"user_tz":-540,"elapsed":4752,"user":{"displayName":"박민혁","userId":"04490186307398600319"}},"outputId":"65ea1a62-e04b-46c9-e903-5692bf9b9b3f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./FokkerPlack/FokkerPlanck'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}],"source":["saver = tf.train.Saver()\n","saver.save(sess, './FokkerPlack/' + saveName)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jA1gNZL58hvp","executionInfo":{"status":"ok","timestamp":1658244172231,"user_tz":-540,"elapsed":4,"user":{"displayName":"박민혁","userId":"04490186307398600319"}}},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Tensorflow1.7","language":"python","name":"tensorflow1.7"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"(Need tf v1 support from google might not work in future) Deep Galerkin Method (DGM)_AdamOptimizer.ipynb","provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}